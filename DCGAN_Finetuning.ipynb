{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5VsVQ3fmY3yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c818bbad-3ef8-44df-922a-131859d06113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szB4o-o-ZASl",
        "outputId": "4031b912-201f-479f-f194-af04b600d2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  8129\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# 코드 실행결과의 동일성을 위해 무작위 시드를 설정합니다\n",
        "#manualSeed = 778\n",
        "manualSeed = random.randint(1, 10000) # 만일 새로운 결과를 원한다면 주석을 없애면 됩니다\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "np.random.seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed_all(manualSeed)\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6CNQbBCoZAUs"
      },
      "outputs": [],
      "source": [
        "dataroot = \"/content/drive/MyDrive/dataset_patch_220117/train\"\n",
        "#dataroot = \"/content/drive/MyDrive/dataset_cyst\" #cyst 데이터셋만\n",
        "# dataroot = \"/content/drive/MyDrive/dataset_meta\" #meta 데이터셋만\n",
        "# dataroot = \"/content/drive/MyDrive/dataset_hema\" #hema 데이터셋만\n",
        "workers = 2 #데이터 불러올 때 사용할 쓰레드 개수\n",
        "batch_size = 8\n",
        "image_size = 64\n",
        "nc = 3 #색 채널 개수 (RGB)\n",
        "nz = 100 #벡터 원소개수\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 300\n",
        "lr = 0.0002 #2e-4=0.0002, 1e-4=0.001\n",
        "beta1 = 0.5 #Adam optimizer 하이퍼파라미터 값. 논문처럼 0.5\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cY2bu0n8ZAW6"
      },
      "outputs": [],
      "source": [
        "#데이터셋 만들기\n",
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size), #가운데 부분을 image_size로 자름\n",
        "                               transforms.ToTensor(), #이미지 데이터를 tensor로 바꿈\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #정규화\n",
        "                           ]))\n",
        "# dataloader 정의\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "# GPU 사용여부\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joy-ZMH8IQzx",
        "outputId": "b52ed78e-0222-48f3-eda3-7ac92f481bea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cyst', 'hema', 'meta']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "classes = dataset.classes\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxkUIn40zhTO",
        "outputId": "2e7dff72-b7fc-42c5-bd53-700a4758ab11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[-1.0000, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-0.9765, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-0.9686, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         ...,\n",
            "         [-0.8667, -0.8824, -0.9137,  ...,  0.9843,  0.9137,  0.8667],\n",
            "         [-1.0000, -0.9765, -0.9843,  ...,  0.8667,  0.8118,  0.7725],\n",
            "         [-0.9765, -0.8745, -0.8431,  ...,  0.6471,  0.5686,  0.5294]],\n",
            "\n",
            "        [[-1.0000, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-0.9765, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-0.9686, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         ...,\n",
            "         [-0.8667, -0.8824, -0.9137,  ...,  0.9843,  0.9137,  0.8667],\n",
            "         [-1.0000, -0.9765, -0.9843,  ...,  0.8667,  0.8118,  0.7725],\n",
            "         [-0.9765, -0.8745, -0.8431,  ...,  0.6471,  0.5686,  0.5294]],\n",
            "\n",
            "        [[-1.0000, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-0.9765, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         [-0.9686, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "         ...,\n",
            "         [-0.8667, -0.8824, -0.9137,  ...,  0.9843,  0.9137,  0.8667],\n",
            "         [-1.0000, -0.9765, -0.9843,  ...,  0.8667,  0.8118,  0.7725],\n",
            "         [-0.9765, -0.8745, -0.8431,  ...,  0.6471,  0.5686,  0.5294]]]), 0)\n"
          ]
        }
      ],
      "source": [
        "print(dataset.__getitem__(13))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-4vP9EDItNM",
        "outputId": "1321e304-1543-4264-d40e-84b67a27417f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "681"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auXAlmUfHpxB",
        "outputId": "7f96ba92-71bf-40c8-f1bb-0c810730f123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 0, 0, 0, 2, 0, 2])\n"
          ]
        }
      ],
      "source": [
        "# seed값 확인\n",
        "dataiter = iter(dataloader)\n",
        "images, labels = next(dataiter)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0XwaQGR32rh",
        "outputId": "617f69da-9710-4f5c-daa8-25aabdde3942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 64, 64])\n",
            "0 batch \n",
            " inputs[0][0][0][0] : -0.1450980305671692 \n",
            " labels: tensor([2, 2, 0, 0, 0, 0, 1, 0])\n",
            "torch.Size([8, 3, 64, 64])\n",
            "1 batch \n",
            " inputs[0][0][0][0] : 0.545098066329956 \n",
            " labels: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([8, 3, 64, 64])\n",
            "2 batch \n",
            " inputs[0][0][0][0] : 0.4901961088180542 \n",
            " labels: tensor([0, 2, 2, 0, 0, 0, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "for batch_size, (inputs, labels) in enumerate(dataloader):\n",
        "  print(inputs.size())\n",
        "  print(\"{} batch \\n inputs[0][0][0][0] : {} \\n labels: {}\".format(batch_size, inputs[0][0][0][0], labels))\n",
        "  #print(\"{} batch \\n inputs[0][0][0][0]\".format(batch_size))\n",
        "  if batch_size ==2:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBl-MQtAxDJX"
      },
      "outputs": [],
      "source": [
        "# 화면에 이미지 몇 개 띄우기\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64],padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "#nrow=3, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eoPb_hrJaVGb"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ydvRPK7kAB_"
      },
      "outputs": [],
      "source": [
        "#nn.ConvTranspose2d(input의 채널수, output의 채널 수, kernel size, stride, padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fE9qsQ5taNRc"
      },
      "outputs": [],
      "source": [
        "# Generator Code\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ApUwvsuaNT7",
        "outputId": "ef9df5a2-c87d-427c-ab60-1531bed33977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# multi-gpu 필요하면 설정\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SqXnzEJpaFff"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqous8TlZAZG",
        "outputId": "39151141-52e9-4ae1-c691-1a60dbb45f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2ZBModYTZAbY"
      },
      "outputs": [],
      "source": [
        "# BCELoss 함수의 인스턴스 생성\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 생성자의 학습상태를 확인할 잠재 공간 벡터를 생성 (Generator의 학습 과정 추적 위해)\n",
        "fixed_noise = torch.randn(1, nz, 1, 1, device=device) # 64\n",
        "\n",
        "# 학습에 사용되는 참/거짓의 라벨\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# G와 D에서 사용할 Adam optimizer를 생성\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GDjmB6GycBi7"
      },
      "outputs": [],
      "source": [
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = 1\n",
        "n2 = 1\n",
        "n3 = 1\n",
        "from torchvision.utils import save_image\n",
        "transform = transforms.Grayscale()"
      ],
      "metadata": {
        "id": "9gW9GdA6si7Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WMYxGSY3ZAdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a13f985-cbe1-488f-b1d8-a810ec463123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop...\n",
            "[1/300][0/86]tLoss_D: 1.9393 tLoss_G: 9.6332 tD(x): 0.6611 tD(G(z)): 0.7217 / 0.0001\n",
            "[1/300][50/86]tLoss_D: 0.0173 tLoss_G: 13.6978 tD(x): 0.9840 tD(G(z)): 0.0006 / 0.0000\n",
            "[2/300][0/86]tLoss_D: 0.0067 tLoss_G: 9.9252 tD(x): 0.9951 tD(G(z)): 0.0017 / 0.0001\n",
            "[2/300][50/86]tLoss_D: 1.6949 tLoss_G: 26.9263 tD(x): 0.9992 tD(G(z)): 0.7554 / 0.0000\n",
            "[3/300][0/86]tLoss_D: 0.1522 tLoss_G: 37.7397 tD(x): 0.9103 tD(G(z)): 0.0000 / 0.0000\n",
            "[3/300][50/86]tLoss_D: 0.0002 tLoss_G: 35.1541 tD(x): 0.9998 tD(G(z)): 0.0000 / 0.0000\n",
            "[4/300][0/86]tLoss_D: 0.0000 tLoss_G: 34.3611 tD(x): 1.0000 tD(G(z)): 0.0000 / 0.0000\n",
            "[4/300][50/86]tLoss_D: 0.0001 tLoss_G: 29.3616 tD(x): 0.9999 tD(G(z)): 0.0000 / 0.0000\n",
            "[5/300][0/86]tLoss_D: 0.4004 tLoss_G: 15.9365 tD(x): 0.9908 tD(G(z)): 0.2315 / 0.0000\n",
            "[5/300][50/86]tLoss_D: 2.0413 tLoss_G: 9.9513 tD(x): 0.8054 tD(G(z)): 0.5186 / 0.0001\n",
            "[6/300][0/86]tLoss_D: 4.1584 tLoss_G: 3.5731 tD(x): 0.9604 tD(G(z)): 0.8843 / 0.0452\n",
            "[6/300][50/86]tLoss_D: 1.3040 tLoss_G: 4.7312 tD(x): 0.6932 tD(G(z)): 0.4012 / 0.0125\n",
            "[7/300][0/86]tLoss_D: 3.3251 tLoss_G: 4.3161 tD(x): 0.2061 tD(G(z)): 0.0043 / 0.0414\n",
            "[7/300][50/86]tLoss_D: 0.3304 tLoss_G: 5.9016 tD(x): 0.7469 tD(G(z)): 0.0116 / 0.0035\n",
            "[8/300][0/86]tLoss_D: 0.3260 tLoss_G: 3.3137 tD(x): 0.8510 tD(G(z)): 0.1272 / 0.0667\n",
            "[8/300][50/86]tLoss_D: 0.1936 tLoss_G: 3.4721 tD(x): 0.9807 tD(G(z)): 0.1567 / 0.0344\n",
            "[9/300][0/86]tLoss_D: 0.6695 tLoss_G: 3.6102 tD(x): 0.7368 tD(G(z)): 0.0407 / 0.0579\n",
            "[9/300][50/86]tLoss_D: 0.6314 tLoss_G: 2.8238 tD(x): 0.6753 tD(G(z)): 0.1089 / 0.0943\n",
            "[10/300][0/86]tLoss_D: 1.1343 tLoss_G: 1.5056 tD(x): 0.5828 tD(G(z)): 0.2843 / 0.2406\n",
            "[10/300][50/86]tLoss_D: 1.2154 tLoss_G: 2.2786 tD(x): 0.6151 tD(G(z)): 0.4476 / 0.1347\n",
            "[11/300][0/86]tLoss_D: 2.5412 tLoss_G: 1.7315 tD(x): 0.1348 tD(G(z)): 0.1339 / 0.3378\n",
            "[11/300][50/86]tLoss_D: 1.0865 tLoss_G: 2.2326 tD(x): 0.5321 tD(G(z)): 0.1542 / 0.1479\n",
            "[12/300][0/86]tLoss_D: 0.7763 tLoss_G: 3.7184 tD(x): 0.8553 tD(G(z)): 0.3645 / 0.0383\n",
            "[12/300][50/86]tLoss_D: 1.0355 tLoss_G: 1.7948 tD(x): 0.6489 tD(G(z)): 0.2087 / 0.2564\n",
            "[13/300][0/86]tLoss_D: 2.2138 tLoss_G: 4.3634 tD(x): 0.2001 tD(G(z)): 0.0441 / 0.0803\n",
            "[13/300][50/86]tLoss_D: 0.5647 tLoss_G: 2.8054 tD(x): 0.8173 tD(G(z)): 0.2386 / 0.0959\n",
            "[14/300][0/86]tLoss_D: 0.9779 tLoss_G: 4.2209 tD(x): 0.9438 tD(G(z)): 0.5121 / 0.0196\n",
            "[14/300][50/86]tLoss_D: 0.9541 tLoss_G: 2.4348 tD(x): 0.6215 tD(G(z)): 0.1909 / 0.0958\n",
            "[15/300][0/86]tLoss_D: 2.0424 tLoss_G: 2.3893 tD(x): 0.9798 tD(G(z)): 0.7624 / 0.1595\n",
            "[15/300][50/86]tLoss_D: 0.8193 tLoss_G: 2.1937 tD(x): 0.8377 tD(G(z)): 0.4180 / 0.1354\n",
            "[16/300][0/86]tLoss_D: 0.5452 tLoss_G: 3.5855 tD(x): 0.8433 tD(G(z)): 0.2159 / 0.0482\n",
            "[16/300][50/86]tLoss_D: 0.4859 tLoss_G: 3.1634 tD(x): 0.7902 tD(G(z)): 0.1986 / 0.0656\n",
            "[17/300][0/86]tLoss_D: 1.4570 tLoss_G: 5.1956 tD(x): 0.3354 tD(G(z)): 0.0129 / 0.0284\n",
            "[17/300][50/86]tLoss_D: 0.8179 tLoss_G: 3.1249 tD(x): 0.9175 tD(G(z)): 0.4555 / 0.0605\n",
            "[18/300][0/86]tLoss_D: 1.8615 tLoss_G: 3.2511 tD(x): 0.3107 tD(G(z)): 0.1057 / 0.2453\n",
            "[18/300][50/86]tLoss_D: 0.2418 tLoss_G: 3.3807 tD(x): 0.8889 tD(G(z)): 0.0720 / 0.0403\n",
            "[19/300][0/86]tLoss_D: 0.9719 tLoss_G: 2.3405 tD(x): 0.7218 tD(G(z)): 0.4049 / 0.1128\n",
            "[19/300][50/86]tLoss_D: 0.4254 tLoss_G: 3.9206 tD(x): 0.9116 tD(G(z)): 0.2581 / 0.0239\n",
            "[20/300][0/86]tLoss_D: 1.4485 tLoss_G: 3.0048 tD(x): 0.6147 tD(G(z)): 0.4227 / 0.0994\n",
            "[20/300][50/86]tLoss_D: 0.2602 tLoss_G: 4.3725 tD(x): 0.9803 tD(G(z)): 0.1693 / 0.0216\n",
            "[21/300][0/86]tLoss_D: 0.2643 tLoss_G: 2.9310 tD(x): 0.9734 tD(G(z)): 0.2056 / 0.0591\n",
            "[21/300][50/86]tLoss_D: 0.3436 tLoss_G: 3.2340 tD(x): 0.7810 tD(G(z)): 0.0719 / 0.0670\n",
            "[22/300][0/86]tLoss_D: 1.0226 tLoss_G: 2.9867 tD(x): 0.9801 tD(G(z)): 0.5229 / 0.1099\n",
            "[22/300][50/86]tLoss_D: 0.2173 tLoss_G: 5.4434 tD(x): 0.8390 tD(G(z)): 0.0201 / 0.0083\n",
            "[23/300][0/86]tLoss_D: 0.1272 tLoss_G: 4.1217 tD(x): 0.9214 tD(G(z)): 0.0406 / 0.0274\n",
            "[23/300][50/86]tLoss_D: 0.5086 tLoss_G: 2.7956 tD(x): 0.7209 tD(G(z)): 0.1232 / 0.0711\n",
            "[24/300][0/86]tLoss_D: 1.1023 tLoss_G: 5.4091 tD(x): 0.9754 tD(G(z)): 0.4423 / 0.0164\n",
            "[24/300][50/86]tLoss_D: 0.6359 tLoss_G: 2.9813 tD(x): 0.5837 tD(G(z)): 0.0248 / 0.0919\n",
            "[25/300][0/86]tLoss_D: 0.9793 tLoss_G: 3.4078 tD(x): 0.9868 tD(G(z)): 0.5261 / 0.0782\n",
            "[25/300][50/86]tLoss_D: 0.8885 tLoss_G: 2.9676 tD(x): 0.7888 tD(G(z)): 0.3281 / 0.0650\n",
            "[26/300][0/86]tLoss_D: 0.6972 tLoss_G: 4.9290 tD(x): 0.9750 tD(G(z)): 0.4306 / 0.0139\n",
            "[26/300][50/86]tLoss_D: 0.2207 tLoss_G: 3.4367 tD(x): 0.8719 tD(G(z)): 0.0713 / 0.0502\n",
            "[27/300][0/86]tLoss_D: 2.0258 tLoss_G: 6.4477 tD(x): 0.9957 tD(G(z)): 0.7271 / 0.0030\n",
            "[27/300][50/86]tLoss_D: 0.1976 tLoss_G: 3.9720 tD(x): 0.9745 tD(G(z)): 0.1363 / 0.0211\n",
            "[28/300][0/86]tLoss_D: 0.1757 tLoss_G: 3.3743 tD(x): 0.9861 tD(G(z)): 0.1409 / 0.0360\n",
            "[28/300][50/86]tLoss_D: 0.1437 tLoss_G: 4.1722 tD(x): 0.9355 tD(G(z)): 0.0683 / 0.0320\n",
            "[29/300][0/86]tLoss_D: 6.1155 tLoss_G: 2.7358 tD(x): 0.9988 tD(G(z)): 0.9911 / 0.1841\n",
            "[29/300][50/86]tLoss_D: 0.4217 tLoss_G: 3.4382 tD(x): 0.8835 tD(G(z)): 0.2004 / 0.0544\n",
            "[30/300][0/86]tLoss_D: 0.8277 tLoss_G: 5.2242 tD(x): 0.9593 tD(G(z)): 0.3773 / 0.0132\n",
            "[30/300][50/86]tLoss_D: 0.3744 tLoss_G: 3.2008 tD(x): 0.9691 tD(G(z)): 0.2597 / 0.0508\n",
            "[31/300][0/86]tLoss_D: 0.0477 tLoss_G: 3.4198 tD(x): 0.9913 tD(G(z)): 0.0380 / 0.0454\n",
            "[31/300][50/86]tLoss_D: 0.2555 tLoss_G: 4.5476 tD(x): 0.9398 tD(G(z)): 0.1536 / 0.0164\n",
            "[32/300][0/86]tLoss_D: 0.2855 tLoss_G: 4.9972 tD(x): 0.7871 tD(G(z)): 0.0210 / 0.0156\n",
            "[32/300][50/86]tLoss_D: 0.0650 tLoss_G: 5.9360 tD(x): 0.9448 tD(G(z)): 0.0063 / 0.0036\n",
            "[33/300][0/86]tLoss_D: 1.4490 tLoss_G: 4.6518 tD(x): 0.9985 tD(G(z)): 0.6410 / 0.0190\n",
            "[33/300][50/86]tLoss_D: 1.2664 tLoss_G: 2.4091 tD(x): 0.4639 tD(G(z)): 0.0526 / 0.1821\n",
            "[34/300][0/86]tLoss_D: 0.2094 tLoss_G: 3.4567 tD(x): 0.9052 tD(G(z)): 0.0992 / 0.0476\n",
            "[34/300][50/86]tLoss_D: 0.0945 tLoss_G: 4.2938 tD(x): 0.9459 tD(G(z)): 0.0368 / 0.0194\n",
            "[35/300][0/86]tLoss_D: 1.9586 tLoss_G: 3.2694 tD(x): 0.7620 tD(G(z)): 0.6068 / 0.1020\n",
            "[35/300][50/86]tLoss_D: 0.5431 tLoss_G: 4.8012 tD(x): 0.7185 tD(G(z)): 0.0056 / 0.0183\n",
            "[36/300][0/86]tLoss_D: 0.1141 tLoss_G: 3.9908 tD(x): 0.9259 tD(G(z)): 0.0310 / 0.0344\n",
            "[36/300][50/86]tLoss_D: 0.1809 tLoss_G: 4.2344 tD(x): 0.8717 tD(G(z)): 0.0310 / 0.0209\n",
            "[37/300][0/86]tLoss_D: 1.7532 tLoss_G: 6.9968 tD(x): 0.9790 tD(G(z)): 0.5869 / 0.0041\n",
            "[37/300][50/86]tLoss_D: 0.8980 tLoss_G: 2.9273 tD(x): 0.6585 tD(G(z)): 0.2206 / 0.0868\n",
            "[38/300][0/86]tLoss_D: 0.2547 tLoss_G: 4.5495 tD(x): 0.8475 tD(G(z)): 0.0656 / 0.0208\n",
            "[38/300][50/86]tLoss_D: 0.7188 tLoss_G: 4.9832 tD(x): 0.6733 tD(G(z)): 0.0738 / 0.0144\n",
            "[39/300][0/86]tLoss_D: 0.6278 tLoss_G: 3.0966 tD(x): 0.7589 tD(G(z)): 0.1767 / 0.0753\n",
            "[39/300][50/86]tLoss_D: 0.8546 tLoss_G: 3.7698 tD(x): 0.6195 tD(G(z)): 0.0885 / 0.0359\n",
            "[40/300][0/86]tLoss_D: 0.9634 tLoss_G: 3.0728 tD(x): 0.6261 tD(G(z)): 0.0646 / 0.0848\n",
            "[40/300][50/86]tLoss_D: 0.1975 tLoss_G: 4.1331 tD(x): 0.9905 tD(G(z)): 0.1602 / 0.0274\n",
            "[41/300][0/86]tLoss_D: 1.0708 tLoss_G: 3.3636 tD(x): 0.9453 tD(G(z)): 0.4662 / 0.1134\n",
            "[41/300][50/86]tLoss_D: 0.1751 tLoss_G: 3.6861 tD(x): 0.8612 tD(G(z)): 0.0158 / 0.0357\n",
            "[42/300][0/86]tLoss_D: 0.1367 tLoss_G: 4.0079 tD(x): 0.9083 tD(G(z)): 0.0346 / 0.0332\n",
            "[42/300][50/86]tLoss_D: 0.4189 tLoss_G: 5.3212 tD(x): 0.9305 tD(G(z)): 0.2628 / 0.0118\n",
            "[43/300][0/86]tLoss_D: 0.1320 tLoss_G: 3.9844 tD(x): 0.9100 tD(G(z)): 0.0269 / 0.0262\n",
            "[43/300][50/86]tLoss_D: 0.3165 tLoss_G: 3.7398 tD(x): 0.9873 tD(G(z)): 0.2338 / 0.0325\n",
            "[44/300][0/86]tLoss_D: 0.4129 tLoss_G: 3.4843 tD(x): 0.9582 tD(G(z)): 0.2608 / 0.0542\n",
            "[44/300][50/86]tLoss_D: 0.2075 tLoss_G: 4.7450 tD(x): 0.9840 tD(G(z)): 0.1536 / 0.0176\n",
            "[45/300][0/86]tLoss_D: 0.3949 tLoss_G: 4.2880 tD(x): 0.8176 tD(G(z)): 0.1362 / 0.0520\n",
            "[45/300][50/86]tLoss_D: 0.8705 tLoss_G: 5.1345 tD(x): 0.8785 tD(G(z)): 0.3879 / 0.0108\n",
            "[46/300][0/86]tLoss_D: 1.5035 tLoss_G: 3.0928 tD(x): 0.9856 tD(G(z)): 0.6349 / 0.0778\n",
            "[46/300][50/86]tLoss_D: 0.5807 tLoss_G: 3.9046 tD(x): 0.9687 tD(G(z)): 0.3380 / 0.0258\n",
            "[47/300][0/86]tLoss_D: 1.2482 tLoss_G: 3.9476 tD(x): 0.9933 tD(G(z)): 0.6095 / 0.0329\n",
            "[47/300][50/86]tLoss_D: 0.7150 tLoss_G: 4.2027 tD(x): 0.9126 tD(G(z)): 0.3605 / 0.0285\n",
            "[48/300][0/86]tLoss_D: 0.8126 tLoss_G: 1.7573 tD(x): 0.5652 tD(G(z)): 0.0963 / 0.2049\n",
            "[48/300][50/86]tLoss_D: 0.7265 tLoss_G: 3.4013 tD(x): 0.6162 tD(G(z)): 0.1287 / 0.0824\n",
            "[49/300][0/86]tLoss_D: 2.2338 tLoss_G: 5.0806 tD(x): 0.9901 tD(G(z)): 0.7207 / 0.0222\n",
            "[49/300][50/86]tLoss_D: 0.0995 tLoss_G: 3.5242 tD(x): 0.9565 tD(G(z)): 0.0505 / 0.0396\n",
            "[50/300][0/86]tLoss_D: 1.0335 tLoss_G: 3.1146 tD(x): 0.7651 tD(G(z)): 0.3721 / 0.1105\n",
            "[50/300][50/86]tLoss_D: 0.4389 tLoss_G: 3.8886 tD(x): 0.9095 tD(G(z)): 0.2673 / 0.0349\n",
            "[51/300][0/86]tLoss_D: 0.8332 tLoss_G: 5.0581 tD(x): 0.5910 tD(G(z)): 0.0070 / 0.0274\n",
            "[51/300][50/86]tLoss_D: 0.7914 tLoss_G: 2.4601 tD(x): 0.6720 tD(G(z)): 0.1085 / 0.1094\n",
            "[52/300][0/86]tLoss_D: 0.8478 tLoss_G: 4.4190 tD(x): 0.9345 tD(G(z)): 0.4334 / 0.0166\n",
            "[52/300][50/86]tLoss_D: 0.2892 tLoss_G: 4.2352 tD(x): 0.9867 tD(G(z)): 0.2130 / 0.0621\n",
            "[53/300][0/86]tLoss_D: 2.0085 tLoss_G: 3.1373 tD(x): 0.9795 tD(G(z)): 0.6535 / 0.0988\n",
            "[53/300][50/86]tLoss_D: 1.0686 tLoss_G: 3.0576 tD(x): 0.5168 tD(G(z)): 0.1175 / 0.0903\n",
            "[54/300][0/86]tLoss_D: 0.9375 tLoss_G: 3.9767 tD(x): 0.7554 tD(G(z)): 0.3930 / 0.0382\n",
            "[54/300][50/86]tLoss_D: 0.7584 tLoss_G: 4.1952 tD(x): 0.8909 tD(G(z)): 0.3787 / 0.0184\n",
            "[55/300][0/86]tLoss_D: 0.1033 tLoss_G: 3.8936 tD(x): 0.9360 tD(G(z)): 0.0347 / 0.0262\n",
            "[55/300][50/86]tLoss_D: 0.9763 tLoss_G: 3.2610 tD(x): 0.5385 tD(G(z)): 0.1585 / 0.0780\n",
            "[56/300][0/86]tLoss_D: 0.2207 tLoss_G: 3.8907 tD(x): 0.9901 tD(G(z)): 0.1608 / 0.0610\n",
            "[56/300][50/86]tLoss_D: 0.4303 tLoss_G: 5.0080 tD(x): 0.9507 tD(G(z)): 0.2651 / 0.0102\n",
            "[57/300][0/86]tLoss_D: 1.0426 tLoss_G: 4.2891 tD(x): 0.9808 tD(G(z)): 0.5035 / 0.0429\n",
            "[57/300][50/86]tLoss_D: 1.0789 tLoss_G: 3.8445 tD(x): 0.5106 tD(G(z)): 0.0116 / 0.0440\n",
            "[58/300][0/86]tLoss_D: 0.4894 tLoss_G: 4.6302 tD(x): 0.9796 tD(G(z)): 0.3270 / 0.0130\n",
            "[58/300][50/86]tLoss_D: 0.1242 tLoss_G: 3.6977 tD(x): 0.9409 tD(G(z)): 0.0567 / 0.0327\n",
            "[59/300][0/86]tLoss_D: 0.1203 tLoss_G: 3.9197 tD(x): 0.9270 tD(G(z)): 0.0410 / 0.0258\n",
            "[59/300][50/86]tLoss_D: 0.2753 tLoss_G: 3.6264 tD(x): 0.9281 tD(G(z)): 0.1662 / 0.0377\n",
            "[60/300][0/86]tLoss_D: 0.3801 tLoss_G: 3.3683 tD(x): 0.8097 tD(G(z)): 0.1177 / 0.0454\n",
            "[60/300][50/86]tLoss_D: 0.2262 tLoss_G: 3.9043 tD(x): 0.8930 tD(G(z)): 0.0688 / 0.0409\n",
            "[61/300][0/86]tLoss_D: 0.3962 tLoss_G: 4.3001 tD(x): 0.9719 tD(G(z)): 0.2431 / 0.0185\n",
            "[61/300][50/86]tLoss_D: 0.5359 tLoss_G: 5.1526 tD(x): 0.9949 tD(G(z)): 0.3590 / 0.0087\n",
            "[62/300][0/86]tLoss_D: 0.2292 tLoss_G: 5.2142 tD(x): 0.8837 tD(G(z)): 0.0724 / 0.0614\n",
            "[62/300][50/86]tLoss_D: 0.8207 tLoss_G: 2.9076 tD(x): 0.6155 tD(G(z)): 0.1422 / 0.0831\n",
            "[63/300][0/86]tLoss_D: 0.3601 tLoss_G: 2.8996 tD(x): 0.8198 tD(G(z)): 0.1245 / 0.0610\n",
            "[63/300][50/86]tLoss_D: 0.3289 tLoss_G: 3.6597 tD(x): 0.8793 tD(G(z)): 0.1651 / 0.0329\n",
            "[64/300][0/86]tLoss_D: 1.5431 tLoss_G: 4.1981 tD(x): 0.8702 tD(G(z)): 0.5328 / 0.0450\n",
            "[64/300][50/86]tLoss_D: 0.4098 tLoss_G: 3.8835 tD(x): 0.8236 tD(G(z)): 0.1698 / 0.0483\n",
            "[65/300][0/86]tLoss_D: 0.8379 tLoss_G: 4.3228 tD(x): 0.9859 tD(G(z)): 0.4229 / 0.0659\n",
            "[65/300][50/86]tLoss_D: 0.6515 tLoss_G: 4.1190 tD(x): 0.6072 tD(G(z)): 0.0536 / 0.0461\n",
            "[66/300][0/86]tLoss_D: 0.4379 tLoss_G: 3.4463 tD(x): 0.9970 tD(G(z)): 0.2831 / 0.0671\n",
            "[66/300][50/86]tLoss_D: 0.2642 tLoss_G: 3.6922 tD(x): 0.8548 tD(G(z)): 0.0301 / 0.0269\n",
            "[67/300][0/86]tLoss_D: 2.7328 tLoss_G: 4.2061 tD(x): 0.9985 tD(G(z)): 0.7615 / 0.0837\n",
            "[67/300][50/86]tLoss_D: 0.5565 tLoss_G: 2.6939 tD(x): 0.8266 tD(G(z)): 0.1994 / 0.0955\n",
            "[68/300][0/86]tLoss_D: 0.4377 tLoss_G: 3.7720 tD(x): 0.9535 tD(G(z)): 0.3052 / 0.0344\n",
            "[68/300][50/86]tLoss_D: 0.5724 tLoss_G: 3.9848 tD(x): 0.7397 tD(G(z)): 0.1615 / 0.0650\n",
            "[69/300][0/86]tLoss_D: 0.2433 tLoss_G: 3.2174 tD(x): 0.8446 tD(G(z)): 0.0593 / 0.0654\n",
            "[69/300][50/86]tLoss_D: 0.1101 tLoss_G: 4.2108 tD(x): 0.9339 tD(G(z)): 0.0371 / 0.0256\n",
            "[70/300][0/86]tLoss_D: 0.6087 tLoss_G: 2.6848 tD(x): 0.9928 tD(G(z)): 0.3002 / 0.1219\n",
            "[70/300][50/86]tLoss_D: 0.7987 tLoss_G: 5.7395 tD(x): 0.9354 tD(G(z)): 0.4343 / 0.0067\n",
            "[71/300][0/86]tLoss_D: 0.1665 tLoss_G: 3.1553 tD(x): 0.9605 tD(G(z)): 0.0976 / 0.1717\n",
            "[71/300][50/86]tLoss_D: 0.2279 tLoss_G: 3.7655 tD(x): 0.9120 tD(G(z)): 0.1139 / 0.0370\n",
            "[72/300][0/86]tLoss_D: 0.3315 tLoss_G: 3.7388 tD(x): 0.9960 tD(G(z)): 0.2415 / 0.0405\n",
            "[72/300][50/86]tLoss_D: 1.0973 tLoss_G: 5.2466 tD(x): 0.4262 tD(G(z)): 0.0104 / 0.0179\n",
            "[73/300][0/86]tLoss_D: 0.2533 tLoss_G: 3.9641 tD(x): 0.9719 tD(G(z)): 0.1659 / 0.0444\n",
            "[73/300][50/86]tLoss_D: 0.4343 tLoss_G: 3.3632 tD(x): 0.7872 tD(G(z)): 0.1539 / 0.0660\n",
            "[74/300][0/86]tLoss_D: 0.8767 tLoss_G: 4.4758 tD(x): 0.9979 tD(G(z)): 0.4672 / 0.0151\n",
            "[74/300][50/86]tLoss_D: 0.2501 tLoss_G: 4.5240 tD(x): 0.8443 tD(G(z)): 0.0551 / 0.0520\n",
            "[75/300][0/86]tLoss_D: 0.3862 tLoss_G: 3.9959 tD(x): 0.9949 tD(G(z)): 0.2477 / 0.0586\n",
            "[75/300][50/86]tLoss_D: 0.7682 tLoss_G: 3.7061 tD(x): 0.6209 tD(G(z)): 0.0150 / 0.0325\n",
            "[76/300][0/86]tLoss_D: 0.2687 tLoss_G: 3.5673 tD(x): 0.9845 tD(G(z)): 0.1716 / 0.0479\n",
            "[76/300][50/86]tLoss_D: 0.1089 tLoss_G: 5.2564 tD(x): 0.9438 tD(G(z)): 0.0448 / 0.0275\n",
            "[77/300][0/86]tLoss_D: 0.3893 tLoss_G: 3.1314 tD(x): 0.7628 tD(G(z)): 0.0569 / 0.0875\n",
            "[77/300][50/86]tLoss_D: 0.0821 tLoss_G: 5.8760 tD(x): 0.9990 tD(G(z)): 0.0760 / 0.0115\n",
            "[78/300][0/86]tLoss_D: 0.2447 tLoss_G: 3.7377 tD(x): 0.9673 tD(G(z)): 0.1755 / 0.0678\n",
            "[78/300][50/86]tLoss_D: 0.3620 tLoss_G: 4.0117 tD(x): 0.9517 tD(G(z)): 0.2328 / 0.0298\n",
            "[79/300][0/86]tLoss_D: 0.7110 tLoss_G: 3.8522 tD(x): 0.9985 tD(G(z)): 0.4252 / 0.0344\n",
            "[79/300][50/86]tLoss_D: 0.0703 tLoss_G: 4.5261 tD(x): 0.9899 tD(G(z)): 0.0544 / 0.0241\n",
            "[80/300][0/86]tLoss_D: 0.2424 tLoss_G: 3.6957 tD(x): 0.9957 tD(G(z)): 0.1682 / 0.0557\n",
            "[80/300][50/86]tLoss_D: 0.4575 tLoss_G: 3.7329 tD(x): 0.8861 tD(G(z)): 0.2087 / 0.0400\n",
            "[81/300][0/86]tLoss_D: 0.5272 tLoss_G: 5.6107 tD(x): 0.9979 tD(G(z)): 0.3234 / 0.0103\n",
            "[81/300][50/86]tLoss_D: 0.4516 tLoss_G: 4.5274 tD(x): 0.7599 tD(G(z)): 0.1007 / 0.0198\n",
            "[82/300][0/86]tLoss_D: 1.1327 tLoss_G: 5.0408 tD(x): 0.9982 tD(G(z)): 0.4904 / 0.0106\n",
            "[82/300][50/86]tLoss_D: 0.0274 tLoss_G: 6.4238 tD(x): 0.9950 tD(G(z)): 0.0217 / 0.0083\n",
            "[83/300][0/86]tLoss_D: 0.4512 tLoss_G: 5.2275 tD(x): 0.9990 tD(G(z)): 0.2818 / 0.0093\n",
            "[83/300][50/86]tLoss_D: 0.1289 tLoss_G: 4.9239 tD(x): 0.9022 tD(G(z)): 0.0227 / 0.0297\n",
            "[84/300][0/86]tLoss_D: 0.3410 tLoss_G: 2.8298 tD(x): 0.9385 tD(G(z)): 0.2236 / 0.0688\n",
            "[84/300][50/86]tLoss_D: 0.2006 tLoss_G: 3.8637 tD(x): 0.9768 tD(G(z)): 0.1404 / 0.0341\n",
            "[85/300][0/86]tLoss_D: 0.0952 tLoss_G: 4.0402 tD(x): 0.9845 tD(G(z)): 0.0695 / 0.0411\n",
            "[85/300][50/86]tLoss_D: 0.1626 tLoss_G: 4.2761 tD(x): 0.9514 tD(G(z)): 0.0951 / 0.0260\n",
            "[86/300][0/86]tLoss_D: 0.4813 tLoss_G: 5.4010 tD(x): 0.6921 tD(G(z)): 0.0016 / 0.0076\n",
            "[86/300][50/86]tLoss_D: 0.1724 tLoss_G: 3.5471 tD(x): 0.8897 tD(G(z)): 0.0439 / 0.0972\n",
            "[87/300][0/86]tLoss_D: 1.2602 tLoss_G: 6.4233 tD(x): 0.9997 tD(G(z)): 0.5496 / 0.0093\n",
            "[87/300][50/86]tLoss_D: 0.2364 tLoss_G: 4.3530 tD(x): 0.9315 tD(G(z)): 0.1390 / 0.0160\n",
            "[88/300][0/86]tLoss_D: 0.3401 tLoss_G: 3.9310 tD(x): 0.8268 tD(G(z)): 0.1164 / 0.0405\n",
            "[88/300][50/86]tLoss_D: 0.1353 tLoss_G: 4.1973 tD(x): 0.9374 tD(G(z)): 0.0640 / 0.0268\n",
            "[89/300][0/86]tLoss_D: 0.0641 tLoss_G: 4.4802 tD(x): 0.9767 tD(G(z)): 0.0389 / 0.0258\n",
            "[89/300][50/86]tLoss_D: 0.3402 tLoss_G: 5.4396 tD(x): 0.9997 tD(G(z)): 0.2209 / 0.0119\n",
            "[90/300][0/86]tLoss_D: 0.0519 tLoss_G: 4.6988 tD(x): 0.9797 tD(G(z)): 0.0302 / 0.0168\n",
            "[90/300][50/86]tLoss_D: 0.5106 tLoss_G: 3.8320 tD(x): 0.8197 tD(G(z)): 0.2222 / 0.0395\n",
            "[91/300][0/86]tLoss_D: 0.4481 tLoss_G: 5.5704 tD(x): 0.7230 tD(G(z)): 0.0024 / 0.0161\n",
            "[91/300][50/86]tLoss_D: 0.1756 tLoss_G: 4.2906 tD(x): 0.8818 tD(G(z)): 0.0408 / 0.0190\n",
            "[92/300][0/86]tLoss_D: 0.2828 tLoss_G: 4.7625 tD(x): 0.9277 tD(G(z)): 0.1651 / 0.0173\n",
            "[92/300][50/86]tLoss_D: 0.4611 tLoss_G: 6.2518 tD(x): 0.9824 tD(G(z)): 0.2398 / 0.0062\n",
            "[93/300][0/86]tLoss_D: 0.3579 tLoss_G: 4.4044 tD(x): 0.9977 tD(G(z)): 0.2672 / 0.0203\n",
            "[93/300][50/86]tLoss_D: 0.0626 tLoss_G: 4.8956 tD(x): 0.9777 tD(G(z)): 0.0370 / 0.0186\n",
            "[94/300][0/86]tLoss_D: 0.1996 tLoss_G: 4.6320 tD(x): 0.9921 tD(G(z)): 0.1525 / 0.0216\n",
            "[94/300][50/86]tLoss_D: 0.0122 tLoss_G: 4.7598 tD(x): 0.9996 tD(G(z)): 0.0116 / 0.0235\n",
            "[95/300][0/86]tLoss_D: 2.4029 tLoss_G: 7.6754 tD(x): 0.9983 tD(G(z)): 0.6908 / 0.0496\n",
            "[95/300][50/86]tLoss_D: 0.6315 tLoss_G: 5.2579 tD(x): 0.8271 tD(G(z)): 0.3103 / 0.0094\n",
            "[96/300][0/86]tLoss_D: 1.7569 tLoss_G: 5.3621 tD(x): 0.9641 tD(G(z)): 0.3962 / 0.0599\n",
            "[96/300][50/86]tLoss_D: 0.5217 tLoss_G: 2.8396 tD(x): 0.7691 tD(G(z)): 0.1453 / 0.0856\n",
            "[97/300][0/86]tLoss_D: 0.4878 tLoss_G: 4.8876 tD(x): 0.6595 tD(G(z)): 0.0195 / 0.0354\n",
            "[97/300][50/86]tLoss_D: 0.1214 tLoss_G: 3.7907 tD(x): 0.9820 tD(G(z)): 0.0947 / 0.0325\n",
            "[98/300][0/86]tLoss_D: 0.3127 tLoss_G: 5.9841 tD(x): 0.9375 tD(G(z)): 0.1824 / 0.0057\n",
            "[98/300][50/86]tLoss_D: 0.1997 tLoss_G: 4.9529 tD(x): 0.8577 tD(G(z)): 0.0317 / 0.0162\n",
            "[99/300][0/86]tLoss_D: 0.0935 tLoss_G: 4.5058 tD(x): 0.9612 tD(G(z)): 0.0491 / 0.0234\n",
            "[99/300][50/86]tLoss_D: 0.0780 tLoss_G: 5.5756 tD(x): 0.9688 tD(G(z)): 0.0401 / 0.0057\n",
            "[100/300][0/86]tLoss_D: 0.0986 tLoss_G: 7.1774 tD(x): 0.9469 tD(G(z)): 0.0354 / 0.0063\n",
            "[100/300][50/86]tLoss_D: 0.2492 tLoss_G: 4.8788 tD(x): 0.9794 tD(G(z)): 0.1803 / 0.0195\n",
            "[101/300][0/86]tLoss_D: 0.1030 tLoss_G: 4.6980 tD(x): 0.9783 tD(G(z)): 0.0697 / 0.0124\n",
            "[101/300][50/86]tLoss_D: 0.2833 tLoss_G: 4.4249 tD(x): 0.8650 tD(G(z)): 0.1031 / 0.0430\n",
            "[102/300][0/86]tLoss_D: 0.1863 tLoss_G: 6.2434 tD(x): 0.8489 tD(G(z)): 0.0023 / 0.0046\n",
            "[102/300][50/86]tLoss_D: 0.1880 tLoss_G: 4.1404 tD(x): 0.8776 tD(G(z)): 0.0323 / 0.0280\n",
            "[103/300][0/86]tLoss_D: 0.1405 tLoss_G: 5.2868 tD(x): 0.8924 tD(G(z)): 0.0165 / 0.0172\n",
            "[103/300][50/86]tLoss_D: 0.0627 tLoss_G: 4.9065 tD(x): 0.9831 tD(G(z)): 0.0433 / 0.0162\n",
            "[104/300][0/86]tLoss_D: 0.1635 tLoss_G: 5.2640 tD(x): 0.9987 tD(G(z)): 0.1428 / 0.0240\n",
            "[104/300][50/86]tLoss_D: 0.2767 tLoss_G: 4.3126 tD(x): 0.8376 tD(G(z)): 0.0631 / 0.0197\n",
            "[105/300][0/86]tLoss_D: 0.2372 tLoss_G: 4.4846 tD(x): 0.9125 tD(G(z)): 0.1145 / 0.0440\n",
            "[105/300][50/86]tLoss_D: 0.1871 tLoss_G: 3.4928 tD(x): 0.9810 tD(G(z)): 0.1421 / 0.0451\n",
            "[106/300][0/86]tLoss_D: 0.1409 tLoss_G: 5.2496 tD(x): 0.8817 tD(G(z)): 0.0069 / 0.0097\n",
            "[106/300][50/86]tLoss_D: 0.2591 tLoss_G: 6.1377 tD(x): 0.9893 tD(G(z)): 0.1662 / 0.0071\n",
            "[107/300][0/86]tLoss_D: 1.4842 tLoss_G: 5.5570 tD(x): 0.9991 tD(G(z)): 0.6181 / 0.0098\n",
            "[107/300][50/86]tLoss_D: 0.1894 tLoss_G: 6.1445 tD(x): 0.9913 tD(G(z)): 0.1020 / 0.0046\n",
            "[108/300][0/86]tLoss_D: 0.4092 tLoss_G: 4.7800 tD(x): 0.9974 tD(G(z)): 0.2479 / 0.0195\n",
            "[108/300][50/86]tLoss_D: 0.1135 tLoss_G: 4.6731 tD(x): 0.9465 tD(G(z)): 0.0512 / 0.0181\n",
            "[109/300][0/86]tLoss_D: 0.1221 tLoss_G: 4.4470 tD(x): 0.9962 tD(G(z)): 0.1071 / 0.0253\n",
            "[109/300][50/86]tLoss_D: 0.0333 tLoss_G: 4.5659 tD(x): 0.9876 tD(G(z)): 0.0203 / 0.0229\n",
            "[110/300][0/86]tLoss_D: 0.3745 tLoss_G: 4.6839 tD(x): 0.9974 tD(G(z)): 0.2633 / 0.0199\n",
            "[110/300][50/86]tLoss_D: 0.7062 tLoss_G: 5.0413 tD(x): 0.6793 tD(G(z)): 0.1348 / 0.0167\n",
            "[111/300][0/86]tLoss_D: 0.1596 tLoss_G: 5.3904 tD(x): 0.8908 tD(G(z)): 0.0249 / 0.0264\n",
            "[111/300][50/86]tLoss_D: 0.1039 tLoss_G: 5.3089 tD(x): 0.9276 tD(G(z)): 0.0251 / 0.0178\n",
            "[112/300][0/86]tLoss_D: 0.0373 tLoss_G: 4.1349 tD(x): 0.9892 tD(G(z)): 0.0258 / 0.0262\n",
            "[112/300][50/86]tLoss_D: 0.2380 tLoss_G: 4.7573 tD(x): 0.8194 tD(G(z)): 0.0057 / 0.0140\n",
            "[113/300][0/86]tLoss_D: 0.0448 tLoss_G: 4.6066 tD(x): 0.9848 tD(G(z)): 0.0285 / 0.0154\n",
            "[113/300][50/86]tLoss_D: 0.1763 tLoss_G: 4.5395 tD(x): 0.9288 tD(G(z)): 0.0765 / 0.0245\n",
            "[114/300][0/86]tLoss_D: 0.1118 tLoss_G: 5.9221 tD(x): 0.9112 tD(G(z)): 0.0051 / 0.0061\n",
            "[114/300][50/86]tLoss_D: 0.2059 tLoss_G: 6.7938 tD(x): 0.9981 tD(G(z)): 0.1308 / 0.0043\n",
            "[115/300][0/86]tLoss_D: 1.4818 tLoss_G: 8.1875 tD(x): 0.9960 tD(G(z)): 0.5123 / 0.0012\n",
            "[115/300][50/86]tLoss_D: 0.7412 tLoss_G: 6.2912 tD(x): 0.9782 tD(G(z)): 0.3259 / 0.0089\n",
            "[116/300][0/86]tLoss_D: 2.2199 tLoss_G: 5.9217 tD(x): 0.9408 tD(G(z)): 0.7339 / 0.0178\n",
            "[116/300][50/86]tLoss_D: 0.1882 tLoss_G: 5.6697 tD(x): 0.9781 tD(G(z)): 0.1078 / 0.0088\n",
            "[117/300][0/86]tLoss_D: 0.3441 tLoss_G: 3.6222 tD(x): 0.9618 tD(G(z)): 0.2349 / 0.0572\n",
            "[117/300][50/86]tLoss_D: 0.1314 tLoss_G: 6.1505 tD(x): 0.9945 tD(G(z)): 0.0965 / 0.0228\n",
            "[118/300][0/86]tLoss_D: 0.1522 tLoss_G: 4.7906 tD(x): 0.9889 tD(G(z)): 0.1005 / 0.0106\n",
            "[118/300][50/86]tLoss_D: 0.5452 tLoss_G: 4.2124 tD(x): 0.6369 tD(G(z)): 0.0089 / 0.0347\n",
            "[119/300][0/86]tLoss_D: 0.1144 tLoss_G: 4.7126 tD(x): 0.9268 tD(G(z)): 0.0345 / 0.0144\n",
            "[119/300][50/86]tLoss_D: 0.0077 tLoss_G: 5.9122 tD(x): 0.9976 tD(G(z)): 0.0052 / 0.0037\n",
            "[120/300][0/86]tLoss_D: 3.0508 tLoss_G: 27.3200 tD(x): 1.0000 tD(G(z)): 0.7113 / 0.0000\n",
            "[120/300][50/86]tLoss_D: 0.1933 tLoss_G: 16.6482 tD(x): 0.8720 tD(G(z)): 0.0000 / 0.0000\n",
            "[121/300][0/86]tLoss_D: 2.3973 tLoss_G: 15.8981 tD(x): 0.9999 tD(G(z)): 0.7457 / 0.0000\n",
            "[121/300][50/86]tLoss_D: 0.4057 tLoss_G: 14.4657 tD(x): 0.9997 tD(G(z)): 0.2115 / 0.0000\n",
            "[122/300][0/86]tLoss_D: 2.2666 tLoss_G: 14.7137 tD(x): 0.9999 tD(G(z)): 0.6888 / 0.0003\n",
            "[122/300][50/86]tLoss_D: 0.3251 tLoss_G: 5.1831 tD(x): 0.8456 tD(G(z)): 0.0097 / 0.0102\n",
            "[123/300][0/86]tLoss_D: 6.6481 tLoss_G: 11.3098 tD(x): 1.0000 tD(G(z)): 0.9884 / 0.0015\n",
            "[123/300][50/86]tLoss_D: 0.0338 tLoss_G: 5.5451 tD(x): 0.9996 tD(G(z)): 0.0324 / 0.0062\n",
            "[124/300][0/86]tLoss_D: 0.0230 tLoss_G: 4.7376 tD(x): 0.9999 tD(G(z)): 0.0224 / 0.0257\n",
            "[124/300][50/86]tLoss_D: 0.0796 tLoss_G: 5.4682 tD(x): 0.9917 tD(G(z)): 0.0667 / 0.0063\n",
            "[125/300][0/86]tLoss_D: 3.3820 tLoss_G: 8.8345 tD(x): 1.0000 tD(G(z)): 0.7161 / 0.0008\n",
            "[125/300][50/86]tLoss_D: 0.0113 tLoss_G: 6.6975 tD(x): 1.0000 tD(G(z)): 0.0112 / 0.0036\n",
            "[126/300][0/86]tLoss_D: 0.0027 tLoss_G: 7.6489 tD(x): 0.9995 tD(G(z)): 0.0022 / 0.0045\n",
            "[126/300][50/86]tLoss_D: 0.0073 tLoss_G: 5.8366 tD(x): 1.0000 tD(G(z)): 0.0072 / 0.0043\n",
            "[127/300][0/86]tLoss_D: 0.0573 tLoss_G: 6.0350 tD(x): 0.9555 tD(G(z)): 0.0051 / 0.0049\n",
            "[127/300][50/86]tLoss_D: 0.2490 tLoss_G: 3.6564 tD(x): 0.8598 tD(G(z)): 0.0298 / 0.0461\n",
            "[128/300][0/86]tLoss_D: 0.0079 tLoss_G: 8.7664 tD(x): 0.9938 tD(G(z)): 0.0016 / 0.0019\n",
            "[128/300][50/86]tLoss_D: 0.2372 tLoss_G: 5.6197 tD(x): 0.8062 tD(G(z)): 0.0015 / 0.0044\n",
            "[129/300][0/86]tLoss_D: 0.0122 tLoss_G: 5.2301 tD(x): 0.9988 tD(G(z)): 0.0109 / 0.0073\n",
            "[129/300][50/86]tLoss_D: 0.0902 tLoss_G: 5.0253 tD(x): 0.9317 tD(G(z)): 0.0107 / 0.0108\n",
            "[130/300][0/86]tLoss_D: 0.0524 tLoss_G: 19.1766 tD(x): 0.9520 tD(G(z)): 0.0000 / 0.0000\n",
            "[130/300][50/86]tLoss_D: 0.3374 tLoss_G: 6.9827 tD(x): 0.7921 tD(G(z)): 0.0005 / 0.0023\n",
            "[131/300][0/86]tLoss_D: 0.2337 tLoss_G: 4.8301 tD(x): 0.9999 tD(G(z)): 0.1914 / 0.0142\n",
            "[131/300][50/86]tLoss_D: 0.0112 tLoss_G: 7.7096 tD(x): 0.9949 tD(G(z)): 0.0060 / 0.0031\n",
            "[132/300][0/86]tLoss_D: 0.1879 tLoss_G: 9.0596 tD(x): 0.9973 tD(G(z)): 0.1454 / 0.0004\n",
            "[132/300][50/86]tLoss_D: 0.0205 tLoss_G: 6.0480 tD(x): 0.9872 tD(G(z)): 0.0075 / 0.0052\n",
            "[133/300][0/86]tLoss_D: 0.0332 tLoss_G: 6.4401 tD(x): 0.9708 tD(G(z)): 0.0032 / 0.0032\n",
            "[133/300][50/86]tLoss_D: 0.0613 tLoss_G: 5.3571 tD(x): 0.9847 tD(G(z)): 0.0422 / 0.0174\n",
            "[134/300][0/86]tLoss_D: 1.7571 tLoss_G: 10.1081 tD(x): 0.9996 tD(G(z)): 0.7289 / 0.0003\n",
            "[134/300][50/86]tLoss_D: 0.8327 tLoss_G: 9.7321 tD(x): 0.9330 tD(G(z)): 0.3875 / 0.0004\n",
            "[135/300][0/86]tLoss_D: 0.0024 tLoss_G: 9.1932 tD(x): 0.9980 tD(G(z)): 0.0004 / 0.0002\n",
            "[135/300][50/86]tLoss_D: 0.0791 tLoss_G: 7.9181 tD(x): 0.9895 tD(G(z)): 0.0620 / 0.0124\n",
            "[136/300][0/86]tLoss_D: 0.0625 tLoss_G: 4.7315 tD(x): 0.9993 tD(G(z)): 0.0565 / 0.0221\n",
            "[136/300][50/86]tLoss_D: 0.2277 tLoss_G: 4.3653 tD(x): 0.8564 tD(G(z)): 0.0266 / 0.0219\n",
            "[137/300][0/86]tLoss_D: 0.0012 tLoss_G: 8.4513 tD(x): 0.9994 tD(G(z)): 0.0006 / 0.0007\n",
            "[137/300][50/86]tLoss_D: 0.0105 tLoss_G: 5.7929 tD(x): 0.9992 tD(G(z)): 0.0096 / 0.0045\n",
            "[138/300][0/86]tLoss_D: 0.0056 tLoss_G: 8.0462 tD(x): 0.9953 tD(G(z)): 0.0008 / 0.0008\n",
            "[138/300][50/86]tLoss_D: 0.0133 tLoss_G: 5.3051 tD(x): 0.9985 tD(G(z)): 0.0117 / 0.0054\n",
            "[139/300][0/86]tLoss_D: 0.0123 tLoss_G: 5.2930 tD(x): 0.9999 tD(G(z)): 0.0120 / 0.0228\n",
            "[139/300][50/86]tLoss_D: 0.0138 tLoss_G: 7.7685 tD(x): 0.9912 tD(G(z)): 0.0049 / 0.0022\n",
            "[140/300][0/86]tLoss_D: 0.0050 tLoss_G: 5.2122 tD(x): 0.9981 tD(G(z)): 0.0031 / 0.0819\n",
            "[140/300][50/86]tLoss_D: 0.0453 tLoss_G: 8.0690 tD(x): 0.9628 tD(G(z)): 0.0061 / 0.0065\n",
            "[141/300][0/86]tLoss_D: 0.0017 tLoss_G: 12.3362 tD(x): 0.9983 tD(G(z)): 0.0000 / 0.0000\n",
            "[141/300][50/86]tLoss_D: 0.2669 tLoss_G: 5.1877 tD(x): 0.9838 tD(G(z)): 0.1993 / 0.0166\n",
            "[142/300][0/86]tLoss_D: 0.0116 tLoss_G: 6.1386 tD(x): 0.9990 tD(G(z)): 0.0105 / 0.0066\n",
            "[142/300][50/86]tLoss_D: 0.0251 tLoss_G: 9.5555 tD(x): 0.9763 tD(G(z)): 0.0001 / 0.0001\n",
            "[143/300][0/86]tLoss_D: 0.0075 tLoss_G: 8.9152 tD(x): 0.9930 tD(G(z)): 0.0004 / 0.0003\n",
            "[143/300][50/86]tLoss_D: 0.0089 tLoss_G: 7.0489 tD(x): 0.9981 tD(G(z)): 0.0068 / 0.0042\n",
            "[144/300][0/86]tLoss_D: 0.0035 tLoss_G: 6.7282 tD(x): 0.9996 tD(G(z)): 0.0031 / 0.0030\n",
            "[144/300][50/86]tLoss_D: 0.0140 tLoss_G: 5.3532 tD(x): 0.9962 tD(G(z)): 0.0101 / 0.0062\n",
            "[145/300][0/86]tLoss_D: 0.0167 tLoss_G: 6.0074 tD(x): 0.9989 tD(G(z)): 0.0153 / 0.0057\n",
            "[145/300][50/86]tLoss_D: 0.0110 tLoss_G: 8.0091 tD(x): 0.9952 tD(G(z)): 0.0061 / 0.0015\n",
            "[146/300][0/86]tLoss_D: 0.0160 tLoss_G: 4.8908 tD(x): 0.9998 tD(G(z)): 0.0156 / 0.0304\n",
            "[146/300][50/86]tLoss_D: 0.1180 tLoss_G: 7.1806 tD(x): 0.9999 tD(G(z)): 0.1029 / 0.0011\n",
            "[147/300][0/86]tLoss_D: 0.0223 tLoss_G: 5.7339 tD(x): 0.9994 tD(G(z)): 0.0212 / 0.0117\n",
            "[147/300][50/86]tLoss_D: 0.0900 tLoss_G: 7.2452 tD(x): 0.9267 tD(G(z)): 0.0105 / 0.0070\n",
            "[148/300][0/86]tLoss_D: 0.0725 tLoss_G: 10.3334 tD(x): 0.9331 tD(G(z)): 0.0000 / 0.0001\n",
            "[148/300][50/86]tLoss_D: 0.0283 tLoss_G: 4.2979 tD(x): 0.9999 tD(G(z)): 0.0273 / 0.0678\n",
            "[149/300][0/86]tLoss_D: 0.1018 tLoss_G: 5.6460 tD(x): 0.9625 tD(G(z)): 0.0542 / 0.0119\n",
            "[149/300][50/86]tLoss_D: 0.0090 tLoss_G: 6.4926 tD(x): 0.9995 tD(G(z)): 0.0084 / 0.0053\n",
            "[150/300][0/86]tLoss_D: 0.0019 tLoss_G: 7.4768 tD(x): 0.9995 tD(G(z)): 0.0013 / 0.0017\n",
            "[150/300][50/86]tLoss_D: 0.0347 tLoss_G: 6.9925 tD(x): 0.9691 tD(G(z)): 0.0022 / 0.0021\n",
            "[151/300][0/86]tLoss_D: 0.1686 tLoss_G: 5.5272 tD(x): 0.9686 tD(G(z)): 0.1186 / 0.0059\n",
            "[151/300][50/86]tLoss_D: 0.0440 tLoss_G: 4.6985 tD(x): 0.9894 tD(G(z)): 0.0318 / 0.0295\n",
            "[152/300][0/86]tLoss_D: 0.2905 tLoss_G: 8.7509 tD(x): 0.9998 tD(G(z)): 0.2254 / 0.0063\n",
            "[152/300][50/86]tLoss_D: 0.0054 tLoss_G: 6.5703 tD(x): 0.9999 tD(G(z)): 0.0053 / 0.0033\n",
            "[153/300][0/86]tLoss_D: 0.1418 tLoss_G: 3.9405 tD(x): 0.9999 tD(G(z)): 0.1245 / 0.0465\n",
            "[153/300][50/86]tLoss_D: 0.0204 tLoss_G: 7.7735 tD(x): 0.9925 tD(G(z)): 0.0124 / 0.0033\n",
            "[154/300][0/86]tLoss_D: 0.1442 tLoss_G: 6.9607 tD(x): 0.8889 tD(G(z)): 0.0099 / 0.0343\n",
            "[154/300][50/86]tLoss_D: 0.0092 tLoss_G: 6.9338 tD(x): 0.9991 tD(G(z)): 0.0082 / 0.0065\n",
            "[155/300][0/86]tLoss_D: 0.9001 tLoss_G: 9.1241 tD(x): 0.9969 tD(G(z)): 0.5008 / 0.0002\n",
            "[155/300][50/86]tLoss_D: 0.0038 tLoss_G: 7.7258 tD(x): 0.9997 tD(G(z)): 0.0035 / 0.0028\n",
            "[156/300][0/86]tLoss_D: 0.0000 tLoss_G: 12.2241 tD(x): 1.0000 tD(G(z)): 0.0000 / 0.0000\n",
            "[156/300][50/86]tLoss_D: 0.0195 tLoss_G: 5.1255 tD(x): 0.9993 tD(G(z)): 0.0186 / 0.0071\n",
            "[157/300][0/86]tLoss_D: 1.1501 tLoss_G: 10.4144 tD(x): 0.9994 tD(G(z)): 0.5765 / 0.0001\n",
            "[157/300][50/86]tLoss_D: 0.0106 tLoss_G: 12.4994 tD(x): 0.9896 tD(G(z)): 0.0000 / 0.0000\n",
            "[158/300][0/86]tLoss_D: 1.6256 tLoss_G: 26.3913 tD(x): 1.0000 tD(G(z)): 0.7570 / 0.0000\n",
            "[158/300][50/86]tLoss_D: 0.0696 tLoss_G: 8.2079 tD(x): 0.9998 tD(G(z)): 0.0600 / 0.0027\n",
            "[159/300][0/86]tLoss_D: 0.9239 tLoss_G: 9.3209 tD(x): 0.9999 tD(G(z)): 0.3816 / 0.0005\n",
            "[159/300][50/86]tLoss_D: 0.0270 tLoss_G: 8.2297 tD(x): 0.9768 tD(G(z)): 0.0028 / 0.0023\n",
            "[160/300][0/86]tLoss_D: 0.0044 tLoss_G: 6.3568 tD(x): 0.9966 tD(G(z)): 0.0010 / 0.0053\n",
            "[160/300][50/86]tLoss_D: 0.0035 tLoss_G: 6.9932 tD(x): 0.9984 tD(G(z)): 0.0018 / 0.0022\n",
            "[161/300][0/86]tLoss_D: 0.2940 tLoss_G: 3.4489 tD(x): 0.9999 tD(G(z)): 0.1586 / 0.0977\n",
            "[161/300][50/86]tLoss_D: 0.0156 tLoss_G: 7.2047 tD(x): 0.9976 tD(G(z)): 0.0131 / 0.0025\n",
            "[162/300][0/86]tLoss_D: 0.0335 tLoss_G: 11.3830 tD(x): 0.9706 tD(G(z)): 0.0001 / 0.0001\n",
            "[162/300][50/86]tLoss_D: 0.0769 tLoss_G: 5.1546 tD(x): 0.9369 tD(G(z)): 0.0082 / 0.0090\n",
            "[163/300][0/86]tLoss_D: 0.0104 tLoss_G: 5.5115 tD(x): 0.9955 tD(G(z)): 0.0058 / 0.0048\n",
            "[163/300][50/86]tLoss_D: 0.0291 tLoss_G: 10.2299 tD(x): 0.9722 tD(G(z)): 0.0001 / 0.0001\n",
            "[164/300][0/86]tLoss_D: 0.2502 tLoss_G: 2.4692 tD(x): 0.9982 tD(G(z)): 0.2001 / 0.1275\n",
            "[164/300][50/86]tLoss_D: 0.0005 tLoss_G: 9.5183 tD(x): 0.9998 tD(G(z)): 0.0003 / 0.0002\n",
            "[165/300][0/86]tLoss_D: 0.0033 tLoss_G: 9.8587 tD(x): 0.9968 tD(G(z)): 0.0000 / 0.0003\n",
            "[165/300][50/86]tLoss_D: 0.1164 tLoss_G: 6.3493 tD(x): 0.9899 tD(G(z)): 0.0912 / 0.0076\n",
            "[166/300][0/86]tLoss_D: 0.0228 tLoss_G: 2.7228 tD(x): 1.0000 tD(G(z)): 0.0219 / 0.2703\n",
            "[166/300][50/86]tLoss_D: 0.0338 tLoss_G: 9.1988 tD(x): 0.9712 tD(G(z)): 0.0011 / 0.0002\n",
            "[167/300][0/86]tLoss_D: 0.0016 tLoss_G: 8.8632 tD(x): 0.9991 tD(G(z)): 0.0007 / 0.0006\n",
            "[167/300][50/86]tLoss_D: 0.3032 tLoss_G: 7.3227 tD(x): 0.8235 tD(G(z)): 0.0003 / 0.0008\n",
            "[168/300][0/86]tLoss_D: 0.0044 tLoss_G: 5.9673 tD(x): 0.9992 tD(G(z)): 0.0035 / 0.0040\n",
            "[168/300][50/86]tLoss_D: 0.0449 tLoss_G: 5.5603 tD(x): 0.9997 tD(G(z)): 0.0425 / 0.0091\n",
            "[169/300][0/86]tLoss_D: 0.0835 tLoss_G: 5.4125 tD(x): 0.9997 tD(G(z)): 0.0737 / 0.0186\n",
            "[169/300][50/86]tLoss_D: 0.0352 tLoss_G: 6.1671 tD(x): 1.0000 tD(G(z)): 0.0325 / 0.0076\n",
            "[170/300][0/86]tLoss_D: 0.0208 tLoss_G: 6.2592 tD(x): 0.9835 tD(G(z)): 0.0039 / 0.0029\n",
            "[170/300][50/86]tLoss_D: 0.0303 tLoss_G: 5.8929 tD(x): 0.9974 tD(G(z)): 0.0268 / 0.0138\n",
            "[171/300][0/86]tLoss_D: 0.0036 tLoss_G: 6.5037 tD(x): 0.9994 tD(G(z)): 0.0030 / 0.0025\n",
            "[171/300][50/86]tLoss_D: 0.0389 tLoss_G: 5.7841 tD(x): 0.9962 tD(G(z)): 0.0334 / 0.0067\n",
            "[172/300][0/86]tLoss_D: 0.0986 tLoss_G: 4.7639 tD(x): 0.9412 tD(G(z)): 0.0319 / 0.0212\n",
            "[172/300][50/86]tLoss_D: 0.0247 tLoss_G: 7.4068 tD(x): 0.9848 tD(G(z)): 0.0091 / 0.0105\n",
            "[173/300][0/86]tLoss_D: 0.0085 tLoss_G: 6.0634 tD(x): 0.9945 tD(G(z)): 0.0029 / 0.0029\n",
            "[173/300][50/86]tLoss_D: 0.0309 tLoss_G: 6.0487 tD(x): 0.9971 tD(G(z)): 0.0271 / 0.0114\n",
            "[174/300][0/86]tLoss_D: 0.3031 tLoss_G: 6.2365 tD(x): 0.8007 tD(G(z)): 0.0007 / 0.0061\n",
            "[174/300][50/86]tLoss_D: 0.0816 tLoss_G: 5.8209 tD(x): 0.9358 tD(G(z)): 0.0050 / 0.0031\n",
            "[175/300][0/86]tLoss_D: 0.0024 tLoss_G: 7.0043 tD(x): 1.0000 tD(G(z)): 0.0024 / 0.0018\n",
            "[175/300][50/86]tLoss_D: 0.1751 tLoss_G: 3.3122 tD(x): 0.8795 tD(G(z)): 0.0293 / 0.0446\n",
            "[176/300][0/86]tLoss_D: 0.0023 tLoss_G: 9.5763 tD(x): 0.9979 tD(G(z)): 0.0002 / 0.0001\n",
            "[176/300][50/86]tLoss_D: 0.0103 tLoss_G: 8.3173 tD(x): 0.9987 tD(G(z)): 0.0089 / 0.0008\n",
            "[177/300][0/86]tLoss_D: 0.0118 tLoss_G: 8.5537 tD(x): 0.9918 tD(G(z)): 0.0035 / 0.0026\n",
            "[177/300][50/86]tLoss_D: 0.0063 tLoss_G: 9.4614 tD(x): 0.9942 tD(G(z)): 0.0003 / 0.0003\n",
            "[178/300][0/86]tLoss_D: 0.0197 tLoss_G: 7.4167 tD(x): 0.9829 tD(G(z)): 0.0022 / 0.0022\n",
            "[178/300][50/86]tLoss_D: 0.3686 tLoss_G: 8.5954 tD(x): 1.0000 tD(G(z)): 0.1326 / 0.0028\n",
            "[179/300][0/86]tLoss_D: 0.2561 tLoss_G: 7.9308 tD(x): 0.9999 tD(G(z)): 0.1930 / 0.0015\n",
            "[179/300][50/86]tLoss_D: 0.1353 tLoss_G: 6.6580 tD(x): 0.9987 tD(G(z)): 0.1083 / 0.0025\n",
            "[180/300][0/86]tLoss_D: 0.0116 tLoss_G: 7.7267 tD(x): 0.9896 tD(G(z)): 0.0010 / 0.0012\n",
            "[180/300][50/86]tLoss_D: 0.0427 tLoss_G: 5.2406 tD(x): 0.9924 tD(G(z)): 0.0340 / 0.0085\n",
            "[181/300][0/86]tLoss_D: 0.0132 tLoss_G: 3.8298 tD(x): 0.9962 tD(G(z)): 0.0092 / 0.1899\n",
            "[181/300][50/86]tLoss_D: 0.0235 tLoss_G: 5.5405 tD(x): 1.0000 tD(G(z)): 0.0230 / 0.0057\n",
            "[182/300][0/86]tLoss_D: 0.0266 tLoss_G: 6.1926 tD(x): 0.9953 tD(G(z)): 0.0213 / 0.0089\n",
            "[182/300][50/86]tLoss_D: 0.0151 tLoss_G: 8.9888 tD(x): 0.9859 tD(G(z)): 0.0006 / 0.0004\n",
            "[183/300][0/86]tLoss_D: 2.3581 tLoss_G: 14.4695 tD(x): 0.9972 tD(G(z)): 0.6795 / 0.0003\n",
            "[183/300][50/86]tLoss_D: 0.4681 tLoss_G: 11.2963 tD(x): 0.9967 tD(G(z)): 0.2380 / 0.0001\n",
            "[184/300][0/86]tLoss_D: 0.0054 tLoss_G: 6.9581 tD(x): 0.9998 tD(G(z)): 0.0051 / 0.0039\n",
            "[184/300][50/86]tLoss_D: 0.8855 tLoss_G: 3.7065 tD(x): 0.6706 tD(G(z)): 0.1115 / 0.0855\n",
            "[185/300][0/86]tLoss_D: 0.1635 tLoss_G: 4.3133 tD(x): 0.9997 tD(G(z)): 0.1329 / 0.0817\n",
            "[185/300][50/86]tLoss_D: 0.0172 tLoss_G: 5.0311 tD(x): 0.9998 tD(G(z)): 0.0168 / 0.0096\n",
            "[186/300][0/86]tLoss_D: 0.0164 tLoss_G: 6.3532 tD(x): 0.9901 tD(G(z)): 0.0062 / 0.0039\n",
            "[186/300][50/86]tLoss_D: 0.3989 tLoss_G: 3.8586 tD(x): 0.7687 tD(G(z)): 0.0119 / 0.0266\n",
            "[187/300][0/86]tLoss_D: 0.6286 tLoss_G: 4.3476 tD(x): 1.0000 tD(G(z)): 0.3843 / 0.0394\n",
            "[187/300][50/86]tLoss_D: 0.2178 tLoss_G: 7.4208 tD(x): 0.9995 tD(G(z)): 0.1423 / 0.0041\n",
            "[188/300][0/86]tLoss_D: 0.1345 tLoss_G: 4.9299 tD(x): 0.9115 tD(G(z)): 0.0325 / 0.0132\n",
            "[188/300][50/86]tLoss_D: 0.0706 tLoss_G: 4.6763 tD(x): 0.9990 tD(G(z)): 0.0650 / 0.0179\n",
            "[189/300][0/86]tLoss_D: 0.0003 tLoss_G: 12.8033 tD(x): 0.9997 tD(G(z)): 0.0000 / 0.0000\n",
            "[189/300][50/86]tLoss_D: 0.0558 tLoss_G: 4.9413 tD(x): 0.9967 tD(G(z)): 0.0497 / 0.0120\n",
            "[190/300][0/86]tLoss_D: 0.0041 tLoss_G: 8.2050 tD(x): 0.9975 tD(G(z)): 0.0016 / 0.0016\n",
            "[190/300][50/86]tLoss_D: 0.0393 tLoss_G: 7.6512 tD(x): 0.9646 tD(G(z)): 0.0020 / 0.0020\n",
            "[191/300][0/86]tLoss_D: 0.0149 tLoss_G: 4.1625 tD(x): 0.9993 tD(G(z)): 0.0140 / 0.0473\n",
            "[191/300][50/86]tLoss_D: 0.1047 tLoss_G: 6.1552 tD(x): 0.9276 tD(G(z)): 0.0045 / 0.0041\n",
            "[192/300][0/86]tLoss_D: 0.0025 tLoss_G: 7.0872 tD(x): 1.0000 tD(G(z)): 0.0025 / 0.0017\n",
            "[192/300][50/86]tLoss_D: 0.0022 tLoss_G: 7.9799 tD(x): 0.9989 tD(G(z)): 0.0010 / 0.0008\n",
            "[193/300][0/86]tLoss_D: 0.0671 tLoss_G: 4.8416 tD(x): 0.9998 tD(G(z)): 0.0617 / 0.0148\n",
            "[193/300][50/86]tLoss_D: 0.3201 tLoss_G: 13.5785 tD(x): 0.8183 tD(G(z)): 0.0000 / 0.0000\n",
            "[194/300][0/86]tLoss_D: 0.0093 tLoss_G: 6.2856 tD(x): 0.9993 tD(G(z)): 0.0085 / 0.0048\n",
            "[194/300][50/86]tLoss_D: 0.0377 tLoss_G: 5.1432 tD(x): 0.9970 tD(G(z)): 0.0337 / 0.0149\n",
            "[195/300][0/86]tLoss_D: 0.2546 tLoss_G: 7.4231 tD(x): 0.9848 tD(G(z)): 0.1797 / 0.0026\n",
            "[195/300][50/86]tLoss_D: 0.0993 tLoss_G: 5.8965 tD(x): 0.9911 tD(G(z)): 0.0803 / 0.0080\n",
            "[196/300][0/86]tLoss_D: 0.0273 tLoss_G: 4.5363 tD(x): 0.9925 tD(G(z)): 0.0190 / 0.0211\n",
            "[196/300][50/86]tLoss_D: 0.0215 tLoss_G: 5.5509 tD(x): 0.9998 tD(G(z)): 0.0209 / 0.0087\n",
            "[197/300][0/86]tLoss_D: 3.2946 tLoss_G: 11.1562 tD(x): 1.0000 tD(G(z)): 0.7212 / 0.0009\n",
            "[197/300][50/86]tLoss_D: 0.0045 tLoss_G: 11.0137 tD(x): 0.9987 tD(G(z)): 0.0031 / 0.0011\n",
            "[198/300][0/86]tLoss_D: 0.2148 tLoss_G: 16.6861 tD(x): 0.8741 tD(G(z)): 0.0000 / 0.0000\n",
            "[198/300][50/86]tLoss_D: 0.0482 tLoss_G: 6.3407 tD(x): 0.9972 tD(G(z)): 0.0436 / 0.0120\n",
            "[199/300][0/86]tLoss_D: 0.0404 tLoss_G: 2.8892 tD(x): 0.9993 tD(G(z)): 0.0376 / 0.1197\n",
            "[199/300][50/86]tLoss_D: 0.0921 tLoss_G: 5.5811 tD(x): 1.0000 tD(G(z)): 0.0860 / 0.0064\n",
            "[200/300][0/86]tLoss_D: 0.0572 tLoss_G: 5.6177 tD(x): 0.9979 tD(G(z)): 0.0518 / 0.0104\n",
            "[200/300][50/86]tLoss_D: 0.0074 tLoss_G: 7.1607 tD(x): 0.9965 tD(G(z)): 0.0038 / 0.0032\n",
            "[201/300][0/86]tLoss_D: 0.0069 tLoss_G: 7.6584 tD(x): 0.9964 tD(G(z)): 0.0033 / 0.0015\n",
            "[201/300][50/86]tLoss_D: 0.0120 tLoss_G: 6.1812 tD(x): 0.9997 tD(G(z)): 0.0115 / 0.0031\n",
            "[202/300][0/86]tLoss_D: 0.0055 tLoss_G: 7.5016 tD(x): 0.9968 tD(G(z)): 0.0022 / 0.0023\n",
            "[202/300][50/86]tLoss_D: 0.0599 tLoss_G: 5.9373 tD(x): 0.9997 tD(G(z)): 0.0563 / 0.0140\n",
            "[203/300][0/86]tLoss_D: 0.5202 tLoss_G: 4.5017 tD(x): 0.9996 tD(G(z)): 0.3551 / 0.0352\n",
            "[203/300][50/86]tLoss_D: 0.1376 tLoss_G: 5.5881 tD(x): 0.8953 tD(G(z)): 0.0151 / 0.0090\n",
            "[204/300][0/86]tLoss_D: 0.0224 tLoss_G: 5.8895 tD(x): 0.9989 tD(G(z)): 0.0201 / 0.0092\n",
            "[204/300][50/86]tLoss_D: 0.3706 tLoss_G: 3.4599 tD(x): 0.7963 tD(G(z)): 0.0280 / 0.0861\n",
            "[205/300][0/86]tLoss_D: 0.0188 tLoss_G: 7.2989 tD(x): 0.9926 tD(G(z)): 0.0109 / 0.0045\n",
            "[205/300][50/86]tLoss_D: 0.0138 tLoss_G: 6.6331 tD(x): 0.9997 tD(G(z)): 0.0134 / 0.0029\n",
            "[206/300][0/86]tLoss_D: 0.7574 tLoss_G: 5.4061 tD(x): 0.9985 tD(G(z)): 0.2886 / 0.0539\n",
            "[206/300][50/86]tLoss_D: 0.0050 tLoss_G: 6.3651 tD(x): 0.9995 tD(G(z)): 0.0044 / 0.0024\n",
            "[207/300][0/86]tLoss_D: 0.1154 tLoss_G: 3.7068 tD(x): 0.9282 tD(G(z)): 0.0090 / 0.0535\n",
            "[207/300][50/86]tLoss_D: 0.0047 tLoss_G: 8.1718 tD(x): 0.9977 tD(G(z)): 0.0024 / 0.0015\n",
            "[208/300][0/86]tLoss_D: 0.0665 tLoss_G: 4.7133 tD(x): 0.9614 tD(G(z)): 0.0221 / 0.0157\n",
            "[208/300][50/86]tLoss_D: 0.0127 tLoss_G: 5.7062 tD(x): 0.9994 tD(G(z)): 0.0120 / 0.0060\n",
            "[209/300][0/86]tLoss_D: 1.2477 tLoss_G: 8.9283 tD(x): 0.9999 tD(G(z)): 0.5343 / 0.0010\n",
            "[209/300][50/86]tLoss_D: 0.0086 tLoss_G: 7.4467 tD(x): 0.9979 tD(G(z)): 0.0064 / 0.0041\n",
            "[210/300][0/86]tLoss_D: 0.1702 tLoss_G: 4.2516 tD(x): 0.9959 tD(G(z)): 0.1304 / 0.0313\n",
            "[210/300][50/86]tLoss_D: 0.0094 tLoss_G: 6.2479 tD(x): 0.9992 tD(G(z)): 0.0085 / 0.0067\n",
            "[211/300][0/86]tLoss_D: 0.1955 tLoss_G: 7.0761 tD(x): 1.0000 tD(G(z)): 0.1490 / 0.0025\n",
            "[211/300][50/86]tLoss_D: 0.0648 tLoss_G: 4.9391 tD(x): 0.9772 tD(G(z)): 0.0382 / 0.0094\n",
            "[212/300][0/86]tLoss_D: 0.0754 tLoss_G: 8.2476 tD(x): 0.9382 tD(G(z)): 0.0026 / 0.0102\n",
            "[212/300][50/86]tLoss_D: 0.1411 tLoss_G: 5.4500 tD(x): 0.9084 tD(G(z)): 0.0079 / 0.0144\n",
            "[213/300][0/86]tLoss_D: 0.2375 tLoss_G: 4.9154 tD(x): 1.0000 tD(G(z)): 0.1834 / 0.0238\n",
            "[213/300][50/86]tLoss_D: 0.0468 tLoss_G: 5.3260 tD(x): 0.9991 tD(G(z)): 0.0428 / 0.0088\n",
            "[214/300][0/86]tLoss_D: 0.0255 tLoss_G: 7.1695 tD(x): 0.9996 tD(G(z)): 0.0244 / 0.0104\n",
            "[214/300][50/86]tLoss_D: 0.0013 tLoss_G: 11.6215 tD(x): 0.9989 tD(G(z)): 0.0003 / 0.0000\n",
            "[215/300][0/86]tLoss_D: 0.0526 tLoss_G: 10.6187 tD(x): 0.9530 tD(G(z)): 0.0001 / 0.0001\n",
            "[215/300][50/86]tLoss_D: 0.0919 tLoss_G: 4.9974 tD(x): 0.9988 tD(G(z)): 0.0845 / 0.0126\n",
            "[216/300][0/86]tLoss_D: 0.4699 tLoss_G: 6.9783 tD(x): 1.0000 tD(G(z)): 0.3383 / 0.0030\n",
            "[216/300][50/86]tLoss_D: 0.1480 tLoss_G: 4.7135 tD(x): 0.9999 tD(G(z)): 0.1320 / 0.0112\n",
            "[217/300][0/86]tLoss_D: 1.9066 tLoss_G: 6.6481 tD(x): 1.0000 tD(G(z)): 0.4550 / 0.0349\n",
            "[217/300][50/86]tLoss_D: 0.7731 tLoss_G: 6.5008 tD(x): 0.9961 tD(G(z)): 0.2071 / 0.0148\n",
            "[218/300][0/86]tLoss_D: 0.4438 tLoss_G: 4.3020 tD(x): 0.7340 tD(G(z)): 0.0155 / 0.0582\n",
            "[218/300][50/86]tLoss_D: 0.0520 tLoss_G: 6.0741 tD(x): 0.9971 tD(G(z)): 0.0466 / 0.0088\n",
            "[219/300][0/86]tLoss_D: 0.6021 tLoss_G: 2.9190 tD(x): 0.9943 tD(G(z)): 0.2630 / 0.1751\n",
            "[219/300][50/86]tLoss_D: 0.0489 tLoss_G: 6.0574 tD(x): 0.9755 tD(G(z)): 0.0225 / 0.0156\n",
            "[220/300][0/86]tLoss_D: 0.1488 tLoss_G: 3.8992 tD(x): 0.9866 tD(G(z)): 0.1107 / 0.1697\n",
            "[220/300][50/86]tLoss_D: 0.0082 tLoss_G: 7.1544 tD(x): 0.9961 tD(G(z)): 0.0042 / 0.0030\n",
            "[221/300][0/86]tLoss_D: 0.0719 tLoss_G: 4.5802 tD(x): 0.9977 tD(G(z)): 0.0631 / 0.0498\n",
            "[221/300][50/86]tLoss_D: 0.4351 tLoss_G: 6.5701 tD(x): 0.9839 tD(G(z)): 0.2126 / 0.0035\n",
            "[222/300][0/86]tLoss_D: 0.0003 tLoss_G: 9.4329 tD(x): 0.9999 tD(G(z)): 0.0002 / 0.0002\n",
            "[222/300][50/86]tLoss_D: 0.0144 tLoss_G: 5.3826 tD(x): 0.9990 tD(G(z)): 0.0132 / 0.0127\n",
            "[223/300][0/86]tLoss_D: 0.0159 tLoss_G: 5.6256 tD(x): 0.9989 tD(G(z)): 0.0143 / 0.0269\n",
            "[223/300][50/86]tLoss_D: 0.0070 tLoss_G: 7.0381 tD(x): 0.9985 tD(G(z)): 0.0054 / 0.0029\n",
            "[224/300][0/86]tLoss_D: 0.6222 tLoss_G: 6.4405 tD(x): 1.0000 tD(G(z)): 0.3186 / 0.0057\n",
            "[224/300][50/86]tLoss_D: 0.0082 tLoss_G: 10.8331 tD(x): 0.9923 tD(G(z)): 0.0004 / 0.0001\n",
            "[225/300][0/86]tLoss_D: 0.0126 tLoss_G: 4.2620 tD(x): 0.9999 tD(G(z)): 0.0123 / 0.0856\n",
            "[225/300][50/86]tLoss_D: 0.0163 tLoss_G: 5.4470 tD(x): 0.9999 tD(G(z)): 0.0160 / 0.0089\n",
            "[226/300][0/86]tLoss_D: 0.3183 tLoss_G: 3.2316 tD(x): 1.0000 tD(G(z)): 0.1940 / 0.0834\n",
            "[226/300][50/86]tLoss_D: 0.6837 tLoss_G: 3.6491 tD(x): 0.8206 tD(G(z)): 0.0329 / 0.0454\n",
            "[227/300][0/86]tLoss_D: 1.4753 tLoss_G: 9.0374 tD(x): 1.0000 tD(G(z)): 0.5273 / 0.0058\n",
            "[227/300][50/86]tLoss_D: 0.0660 tLoss_G: 6.8702 tD(x): 0.9680 tD(G(z)): 0.0266 / 0.0083\n",
            "[228/300][0/86]tLoss_D: 0.0947 tLoss_G: 6.2926 tD(x): 0.9998 tD(G(z)): 0.0668 / 0.0052\n",
            "[228/300][50/86]tLoss_D: 0.0033 tLoss_G: 7.2492 tD(x): 0.9978 tD(G(z)): 0.0011 / 0.0009\n",
            "[229/300][0/86]tLoss_D: 0.0001 tLoss_G: 8.9230 tD(x): 1.0000 tD(G(z)): 0.0001 / 0.0003\n",
            "[229/300][50/86]tLoss_D: 0.0380 tLoss_G: 7.0797 tD(x): 0.9708 tD(G(z)): 0.0051 / 0.0044\n",
            "[230/300][0/86]tLoss_D: 0.0944 tLoss_G: 5.5429 tD(x): 0.9883 tD(G(z)): 0.0668 / 0.0109\n",
            "[230/300][50/86]tLoss_D: 0.0627 tLoss_G: 5.4091 tD(x): 0.9759 tD(G(z)): 0.0347 / 0.0130\n",
            "[231/300][0/86]tLoss_D: 0.0215 tLoss_G: 5.2296 tD(x): 0.9963 tD(G(z)): 0.0173 / 0.0127\n",
            "[231/300][50/86]tLoss_D: 0.0176 tLoss_G: 5.8408 tD(x): 0.9999 tD(G(z)): 0.0170 / 0.0113\n",
            "[232/300][0/86]tLoss_D: 0.0497 tLoss_G: 2.1573 tD(x): 1.0000 tD(G(z)): 0.0461 / 0.2271\n",
            "[232/300][50/86]tLoss_D: 0.1232 tLoss_G: 6.4625 tD(x): 0.9789 tD(G(z)): 0.0827 / 0.0115\n",
            "[233/300][0/86]tLoss_D: 0.3132 tLoss_G: 3.7992 tD(x): 0.9999 tD(G(z)): 0.2360 / 0.0777\n",
            "[233/300][50/86]tLoss_D: 0.1005 tLoss_G: 7.2485 tD(x): 0.9331 tD(G(z)): 0.0178 / 0.0071\n",
            "[234/300][0/86]tLoss_D: 0.0084 tLoss_G: 7.0935 tD(x): 0.9950 tD(G(z)): 0.0033 / 0.0027\n",
            "[234/300][50/86]tLoss_D: 0.1929 tLoss_G: 5.9091 tD(x): 0.9147 tD(G(z)): 0.0708 / 0.0043\n",
            "[235/300][0/86]tLoss_D: 0.0279 tLoss_G: 5.7946 tD(x): 0.9850 tD(G(z)): 0.0123 / 0.0106\n",
            "[235/300][50/86]tLoss_D: 0.0097 tLoss_G: 6.6019 tD(x): 0.9977 tD(G(z)): 0.0073 / 0.0059\n",
            "[236/300][0/86]tLoss_D: 0.0290 tLoss_G: 3.6973 tD(x): 1.0000 tD(G(z)): 0.0278 / 0.1296\n",
            "[236/300][50/86]tLoss_D: 0.1122 tLoss_G: 4.2618 tD(x): 0.9905 tD(G(z)): 0.0952 / 0.0307\n",
            "[237/300][0/86]tLoss_D: 1.8057 tLoss_G: 4.1656 tD(x): 0.3612 tD(G(z)): 0.0020 / 0.0388\n",
            "[237/300][50/86]tLoss_D: 0.1206 tLoss_G: 4.0223 tD(x): 0.9992 tD(G(z)): 0.1093 / 0.0606\n",
            "[238/300][0/86]tLoss_D: 0.4628 tLoss_G: 4.6532 tD(x): 0.9986 tD(G(z)): 0.2654 / 0.0196\n",
            "[238/300][50/86]tLoss_D: 0.0184 tLoss_G: 6.5368 tD(x): 0.9883 tD(G(z)): 0.0065 / 0.0041\n",
            "[239/300][0/86]tLoss_D: 0.1535 tLoss_G: 7.6106 tD(x): 0.9058 tD(G(z)): 0.0042 / 0.0051\n",
            "[239/300][50/86]tLoss_D: 0.0853 tLoss_G: 4.7959 tD(x): 0.9969 tD(G(z)): 0.0757 / 0.0158\n",
            "[240/300][0/86]tLoss_D: 0.0090 tLoss_G: 5.3001 tD(x): 0.9987 tD(G(z)): 0.0077 / 0.0107\n",
            "[240/300][50/86]tLoss_D: 0.4543 tLoss_G: 10.3357 tD(x): 0.7474 tD(G(z)): 0.0000 / 0.0001\n",
            "[241/300][0/86]tLoss_D: 0.0034 tLoss_G: 10.0626 tD(x): 0.9967 tD(G(z)): 0.0001 / 0.0001\n",
            "[241/300][50/86]tLoss_D: 0.1552 tLoss_G: 6.4579 tD(x): 0.8961 tD(G(z)): 0.0188 / 0.0303\n",
            "[242/300][0/86]tLoss_D: 0.0157 tLoss_G: 5.6658 tD(x): 0.9966 tD(G(z)): 0.0121 / 0.0072\n",
            "[242/300][50/86]tLoss_D: 0.4909 tLoss_G: 3.9413 tD(x): 0.9995 tD(G(z)): 0.2794 / 0.0336\n",
            "[243/300][0/86]tLoss_D: 0.0552 tLoss_G: 5.6994 tD(x): 0.9985 tD(G(z)): 0.0486 / 0.0161\n",
            "[243/300][50/86]tLoss_D: 0.0052 tLoss_G: 7.1738 tD(x): 0.9991 tD(G(z)): 0.0043 / 0.0040\n",
            "[244/300][0/86]tLoss_D: 0.0009 tLoss_G: 8.6549 tD(x): 0.9996 tD(G(z)): 0.0004 / 0.0003\n",
            "[244/300][50/86]tLoss_D: 0.1058 tLoss_G: 5.0624 tD(x): 0.9287 tD(G(z)): 0.0268 / 0.0183\n",
            "[245/300][0/86]tLoss_D: 1.6713 tLoss_G: 4.4564 tD(x): 0.9990 tD(G(z)): 0.6799 / 0.0184\n",
            "[245/300][50/86]tLoss_D: 0.0776 tLoss_G: 8.6890 tD(x): 0.9294 tD(G(z)): 0.0006 / 0.0005\n",
            "[246/300][0/86]tLoss_D: 0.4653 tLoss_G: 6.1699 tD(x): 0.6853 tD(G(z)): 0.0002 / 0.0040\n",
            "[246/300][50/86]tLoss_D: 0.0181 tLoss_G: 5.4360 tD(x): 0.9968 tD(G(z)): 0.0148 / 0.0057\n",
            "[247/300][0/86]tLoss_D: 0.0126 tLoss_G: 6.6461 tD(x): 0.9946 tD(G(z)): 0.0072 / 0.0027\n",
            "[247/300][50/86]tLoss_D: 0.0867 tLoss_G: 5.9374 tD(x): 0.9787 tD(G(z)): 0.0537 / 0.0046\n",
            "[248/300][0/86]tLoss_D: 0.1635 tLoss_G: 3.8732 tD(x): 0.9997 tD(G(z)): 0.1304 / 0.0740\n",
            "[248/300][50/86]tLoss_D: 0.0865 tLoss_G: 5.2553 tD(x): 0.9973 tD(G(z)): 0.0734 / 0.0142\n",
            "[249/300][0/86]tLoss_D: 0.0397 tLoss_G: 3.6447 tD(x): 0.9926 tD(G(z)): 0.0316 / 0.0300\n",
            "[249/300][50/86]tLoss_D: 0.0038 tLoss_G: 7.9345 tD(x): 0.9994 tD(G(z)): 0.0032 / 0.0029\n",
            "[250/300][0/86]tLoss_D: 0.0840 tLoss_G: 5.0393 tD(x): 0.9796 tD(G(z)): 0.0555 / 0.0085\n",
            "[250/300][50/86]tLoss_D: 0.0057 tLoss_G: 7.6397 tD(x): 0.9976 tD(G(z)): 0.0033 / 0.0017\n",
            "[251/300][0/86]tLoss_D: 0.0104 tLoss_G: 7.4952 tD(x): 0.9946 tD(G(z)): 0.0050 / 0.0031\n",
            "[251/300][50/86]tLoss_D: 0.1312 tLoss_G: 5.8084 tD(x): 0.9945 tD(G(z)): 0.0972 / 0.0061\n",
            "[252/300][0/86]tLoss_D: 0.0811 tLoss_G: 5.2630 tD(x): 0.9993 tD(G(z)): 0.0652 / 0.0109\n",
            "[252/300][50/86]tLoss_D: 0.0156 tLoss_G: 6.3751 tD(x): 0.9985 tD(G(z)): 0.0139 / 0.0098\n",
            "[253/300][0/86]tLoss_D: 0.0468 tLoss_G: 5.1461 tD(x): 0.9986 tD(G(z)): 0.0433 / 0.0197\n",
            "[253/300][50/86]tLoss_D: 0.0167 tLoss_G: 6.0279 tD(x): 0.9933 tD(G(z)): 0.0098 / 0.0073\n",
            "[254/300][0/86]tLoss_D: 0.0166 tLoss_G: 10.9599 tD(x): 0.9839 tD(G(z)): 0.0001 / 0.0001\n",
            "[254/300][50/86]tLoss_D: 0.0088 tLoss_G: 6.2177 tD(x): 0.9950 tD(G(z)): 0.0037 / 0.0033\n",
            "[255/300][0/86]tLoss_D: 0.0105 tLoss_G: 6.5770 tD(x): 0.9975 tD(G(z)): 0.0078 / 0.0064\n",
            "[255/300][50/86]tLoss_D: 0.3991 tLoss_G: 4.5409 tD(x): 0.7498 tD(G(z)): 0.0249 / 0.0410\n",
            "[256/300][0/86]tLoss_D: 0.0364 tLoss_G: 5.7299 tD(x): 0.9993 tD(G(z)): 0.0342 / 0.0178\n",
            "[256/300][50/86]tLoss_D: 0.0119 tLoss_G: 6.7884 tD(x): 0.9983 tD(G(z)): 0.0100 / 0.0070\n",
            "[257/300][0/86]tLoss_D: 0.0168 tLoss_G: 4.1226 tD(x): 0.9971 tD(G(z)): 0.0137 / 0.1023\n",
            "[257/300][50/86]tLoss_D: 0.0194 tLoss_G: 6.7558 tD(x): 0.9862 tD(G(z)): 0.0049 / 0.0028\n",
            "[258/300][0/86]tLoss_D: 0.0252 tLoss_G: 4.9303 tD(x): 0.9975 tD(G(z)): 0.0222 / 0.0116\n",
            "[258/300][50/86]tLoss_D: 0.0154 tLoss_G: 8.6352 tD(x): 0.9994 tD(G(z)): 0.0141 / 0.0010\n",
            "[259/300][0/86]tLoss_D: 0.3308 tLoss_G: 7.8822 tD(x): 0.9978 tD(G(z)): 0.2183 / 0.0039\n",
            "[259/300][50/86]tLoss_D: 0.0618 tLoss_G: 5.4870 tD(x): 0.9996 tD(G(z)): 0.0566 / 0.0118\n",
            "[260/300][0/86]tLoss_D: 0.0422 tLoss_G: 6.9728 tD(x): 0.9624 tD(G(z)): 0.0023 / 0.0025\n",
            "[260/300][50/86]tLoss_D: 0.1268 tLoss_G: 6.5927 tD(x): 0.8955 tD(G(z)): 0.0093 / 0.0066\n",
            "[261/300][0/86]tLoss_D: 0.0012 tLoss_G: 8.9487 tD(x): 1.0000 tD(G(z)): 0.0011 / 0.0011\n",
            "[261/300][50/86]tLoss_D: 0.0298 tLoss_G: 5.2700 tD(x): 0.9800 tD(G(z)): 0.0084 / 0.0072\n",
            "[262/300][0/86]tLoss_D: 0.9074 tLoss_G: 9.7953 tD(x): 0.9990 tD(G(z)): 0.4614 / 0.0002\n",
            "[262/300][50/86]tLoss_D: 0.0010 tLoss_G: 8.9377 tD(x): 0.9998 tD(G(z)): 0.0008 / 0.0006\n",
            "[263/300][0/86]tLoss_D: 0.0091 tLoss_G: 6.4132 tD(x): 0.9966 tD(G(z)): 0.0056 / 0.0057\n",
            "[263/300][50/86]tLoss_D: 0.0130 tLoss_G: 5.9734 tD(x): 0.9991 tD(G(z)): 0.0120 / 0.0094\n",
            "[264/300][0/86]tLoss_D: 0.0066 tLoss_G: 6.3163 tD(x): 0.9973 tD(G(z)): 0.0039 / 0.0035\n",
            "[264/300][50/86]tLoss_D: 0.0073 tLoss_G: 7.0683 tD(x): 0.9997 tD(G(z)): 0.0068 / 0.0028\n",
            "[265/300][0/86]tLoss_D: 0.2048 tLoss_G: 7.2693 tD(x): 0.9964 tD(G(z)): 0.1488 / 0.0039\n",
            "[265/300][50/86]tLoss_D: 0.0012 tLoss_G: 7.9262 tD(x): 0.9994 tD(G(z)): 0.0006 / 0.0006\n",
            "[266/300][0/86]tLoss_D: 0.0685 tLoss_G: 11.5766 tD(x): 0.9450 tD(G(z)): 0.0001 / 0.0001\n",
            "[266/300][50/86]tLoss_D: 0.0155 tLoss_G: 9.5477 tD(x): 0.9887 tD(G(z)): 0.0038 / 0.0016\n",
            "[267/300][0/86]tLoss_D: 0.1293 tLoss_G: 4.3897 tD(x): 0.9593 tD(G(z)): 0.0773 / 0.0203\n",
            "[267/300][50/86]tLoss_D: 0.0117 tLoss_G: 6.2800 tD(x): 0.9980 tD(G(z)): 0.0095 / 0.0061\n",
            "[268/300][0/86]tLoss_D: 0.0574 tLoss_G: 6.3595 tD(x): 0.9999 tD(G(z)): 0.0530 / 0.0085\n",
            "[268/300][50/86]tLoss_D: 0.4002 tLoss_G: 4.6498 tD(x): 0.7490 tD(G(z)): 0.0182 / 0.0411\n",
            "[269/300][0/86]tLoss_D: 0.0167 tLoss_G: 8.6992 tD(x): 0.9884 tD(G(z)): 0.0048 / 0.0040\n",
            "[269/300][50/86]tLoss_D: 0.0338 tLoss_G: 6.5371 tD(x): 0.9733 tD(G(z)): 0.0054 / 0.0082\n",
            "[270/300][0/86]tLoss_D: 0.0296 tLoss_G: 8.9683 tD(x): 0.9872 tD(G(z)): 0.0162 / 0.0177\n",
            "[270/300][50/86]tLoss_D: 0.9674 tLoss_G: 6.0822 tD(x): 0.6837 tD(G(z)): 0.0004 / 0.0169\n",
            "[271/300][0/86]tLoss_D: 0.0060 tLoss_G: 7.3403 tD(x): 0.9972 tD(G(z)): 0.0032 / 0.0021\n",
            "[271/300][50/86]tLoss_D: 0.0021 tLoss_G: 7.4364 tD(x): 1.0000 tD(G(z)): 0.0020 / 0.0009\n",
            "[272/300][0/86]tLoss_D: 0.1288 tLoss_G: 3.0963 tD(x): 1.0000 tD(G(z)): 0.1088 / 0.0793\n",
            "[272/300][50/86]tLoss_D: 0.0176 tLoss_G: 10.2036 tD(x): 0.9835 tD(G(z)): 0.0004 / 0.0004\n",
            "[273/300][0/86]tLoss_D: 0.0129 tLoss_G: 6.0138 tD(x): 0.9992 tD(G(z)): 0.0119 / 0.0071\n",
            "[273/300][50/86]tLoss_D: 0.2478 tLoss_G: 4.5118 tD(x): 1.0000 tD(G(z)): 0.2119 / 0.0199\n",
            "[274/300][0/86]tLoss_D: 0.0436 tLoss_G: 5.8587 tD(x): 0.9974 tD(G(z)): 0.0384 / 0.0180\n",
            "[274/300][50/86]tLoss_D: 0.0186 tLoss_G: 6.4952 tD(x): 0.9996 tD(G(z)): 0.0176 / 0.0083\n",
            "[275/300][0/86]tLoss_D: 0.1229 tLoss_G: 4.7736 tD(x): 0.9240 tD(G(z)): 0.0246 / 0.0129\n",
            "[275/300][50/86]tLoss_D: 0.0756 tLoss_G: 5.9531 tD(x): 0.9389 tD(G(z)): 0.0042 / 0.0072\n",
            "[276/300][0/86]tLoss_D: 0.0111 tLoss_G: 5.5051 tD(x): 0.9992 tD(G(z)): 0.0102 / 0.0096\n",
            "[276/300][50/86]tLoss_D: 0.0286 tLoss_G: 9.0793 tD(x): 0.9866 tD(G(z)): 0.0139 / 0.0033\n",
            "[277/300][0/86]tLoss_D: 0.4016 tLoss_G: 5.0664 tD(x): 0.8262 tD(G(z)): 0.0922 / 0.0131\n",
            "[277/300][50/86]tLoss_D: 0.0411 tLoss_G: 5.8237 tD(x): 0.9974 tD(G(z)): 0.0364 / 0.0108\n",
            "[278/300][0/86]tLoss_D: 0.5178 tLoss_G: 2.9972 tD(x): 0.7430 tD(G(z)): 0.0252 / 0.1140\n",
            "[278/300][50/86]tLoss_D: 0.2266 tLoss_G: 6.3876 tD(x): 0.9618 tD(G(z)): 0.1358 / 0.0094\n",
            "[279/300][0/86]tLoss_D: 0.0622 tLoss_G: 5.0198 tD(x): 0.9895 tD(G(z)): 0.0488 / 0.0338\n",
            "[279/300][50/86]tLoss_D: 0.0279 tLoss_G: 8.9238 tD(x): 0.9737 tD(G(z)): 0.0008 / 0.0007\n",
            "[280/300][0/86]tLoss_D: 0.0219 tLoss_G: 4.7178 tD(x): 0.9994 tD(G(z)): 0.0209 / 0.0157\n",
            "[280/300][50/86]tLoss_D: 0.1406 tLoss_G: 5.2746 tD(x): 0.9642 tD(G(z)): 0.0820 / 0.0116\n",
            "[281/300][0/86]tLoss_D: 0.0038 tLoss_G: 11.7065 tD(x): 0.9962 tD(G(z)): 0.0000 / 0.0000\n",
            "[281/300][50/86]tLoss_D: 0.0186 tLoss_G: 6.1880 tD(x): 0.9934 tD(G(z)): 0.0118 / 0.0069\n",
            "[282/300][0/86]tLoss_D: 0.1166 tLoss_G: 14.4671 tD(x): 0.9216 tD(G(z)): 0.0001 / 0.0001\n",
            "[282/300][50/86]tLoss_D: 0.0140 tLoss_G: 8.3351 tD(x): 0.9876 tD(G(z)): 0.0015 / 0.0015\n",
            "[283/300][0/86]tLoss_D: 0.4286 tLoss_G: 7.6040 tD(x): 0.7349 tD(G(z)): 0.0078 / 0.0129\n",
            "[283/300][50/86]tLoss_D: 0.0239 tLoss_G: 6.5810 tD(x): 0.9982 tD(G(z)): 0.0215 / 0.0043\n",
            "[284/300][0/86]tLoss_D: 0.8843 tLoss_G: 3.6594 tD(x): 0.7410 tD(G(z)): 0.0589 / 0.0368\n",
            "[284/300][50/86]tLoss_D: 0.0471 tLoss_G: 5.6000 tD(x): 0.9699 tD(G(z)): 0.0149 / 0.0105\n",
            "[285/300][0/86]tLoss_D: 0.2265 tLoss_G: 8.0870 tD(x): 0.9937 tD(G(z)): 0.1635 / 0.0025\n",
            "[285/300][50/86]tLoss_D: 0.0122 tLoss_G: 8.4169 tD(x): 0.9933 tD(G(z)): 0.0054 / 0.0036\n",
            "[286/300][0/86]tLoss_D: 0.0006 tLoss_G: 8.5709 tD(x): 0.9997 tD(G(z)): 0.0004 / 0.0006\n",
            "[286/300][50/86]tLoss_D: 0.0094 tLoss_G: 8.0033 tD(x): 0.9993 tD(G(z)): 0.0085 / 0.0065\n",
            "[287/300][0/86]tLoss_D: 0.0038 tLoss_G: 8.3963 tD(x): 0.9995 tD(G(z)): 0.0033 / 0.0020\n",
            "[287/300][50/86]tLoss_D: 0.0103 tLoss_G: 6.5359 tD(x): 0.9963 tD(G(z)): 0.0065 / 0.0027\n",
            "[288/300][0/86]tLoss_D: 0.0273 tLoss_G: 9.4819 tD(x): 0.9977 tD(G(z)): 0.0227 / 0.0017\n",
            "[288/300][50/86]tLoss_D: 0.0448 tLoss_G: 7.6933 tD(x): 0.9961 tD(G(z)): 0.0362 / 0.0030\n",
            "[289/300][0/86]tLoss_D: 0.1881 tLoss_G: 8.9348 tD(x): 0.9965 tD(G(z)): 0.0985 / 0.0009\n",
            "[289/300][50/86]tLoss_D: 0.5878 tLoss_G: 4.4571 tD(x): 0.7737 tD(G(z)): 0.0296 / 0.0216\n",
            "[290/300][0/86]tLoss_D: 0.0055 tLoss_G: 6.7393 tD(x): 0.9992 tD(G(z)): 0.0047 / 0.0041\n",
            "[290/300][50/86]tLoss_D: 0.1046 tLoss_G: 8.4063 tD(x): 0.9463 tD(G(z)): 0.0383 / 0.0212\n",
            "[291/300][0/86]tLoss_D: 0.0445 tLoss_G: 7.8064 tD(x): 0.9780 tD(G(z)): 0.0204 / 0.0098\n",
            "[291/300][50/86]tLoss_D: 0.1322 tLoss_G: 10.2154 tD(x): 0.8988 tD(G(z)): 0.0014 / 0.0004\n",
            "[292/300][0/86]tLoss_D: 0.4472 tLoss_G: 4.3881 tD(x): 0.6775 tD(G(z)): 0.0053 / 0.0816\n",
            "[292/300][50/86]tLoss_D: 0.0711 tLoss_G: 7.5410 tD(x): 0.9350 tD(G(z)): 0.0009 / 0.0013\n",
            "[293/300][0/86]tLoss_D: 0.0134 tLoss_G: 11.8765 tD(x): 0.9870 tD(G(z)): 0.0001 / 0.0000\n",
            "[293/300][50/86]tLoss_D: 0.1203 tLoss_G: 5.2962 tD(x): 0.9802 tD(G(z)): 0.0777 / 0.0084\n",
            "[294/300][0/86]tLoss_D: 0.0347 tLoss_G: 7.8346 tD(x): 0.9847 tD(G(z)): 0.0184 / 0.0031\n",
            "[294/300][50/86]tLoss_D: 0.0277 tLoss_G: 7.0450 tD(x): 0.9786 tD(G(z)): 0.0058 / 0.0043\n",
            "[295/300][0/86]tLoss_D: 0.0066 tLoss_G: 7.7158 tD(x): 0.9974 tD(G(z)): 0.0040 / 0.0037\n",
            "[295/300][50/86]tLoss_D: 0.0095 tLoss_G: 7.1890 tD(x): 0.9929 tD(G(z)): 0.0024 / 0.0025\n",
            "[296/300][0/86]tLoss_D: 0.0135 tLoss_G: 6.1168 tD(x): 0.9965 tD(G(z)): 0.0098 / 0.0041\n",
            "[296/300][50/86]tLoss_D: 0.0144 tLoss_G: 6.7013 tD(x): 0.9966 tD(G(z)): 0.0109 / 0.0025\n",
            "[297/300][0/86]tLoss_D: 0.0053 tLoss_G: 10.8344 tD(x): 0.9983 tD(G(z)): 0.0035 / 0.0020\n",
            "[297/300][50/86]tLoss_D: 0.0370 tLoss_G: 7.7251 tD(x): 0.9797 tD(G(z)): 0.0149 / 0.0015\n",
            "[298/300][0/86]tLoss_D: 2.7841 tLoss_G: 13.2031 tD(x): 1.0000 tD(G(z)): 0.7527 / 0.0001\n",
            "[298/300][50/86]tLoss_D: 0.1483 tLoss_G: 9.0034 tD(x): 1.0000 tD(G(z)): 0.1293 / 0.0029\n",
            "[299/300][0/86]tLoss_D: 1.6909 tLoss_G: 12.7539 tD(x): 1.0000 tD(G(z)): 0.6165 / 0.0005\n",
            "[299/300][50/86]tLoss_D: 0.8395 tLoss_G: 4.3798 tD(x): 0.6460 tD(G(z)): 0.0050 / 0.1046\n",
            "[300/300][0/86]tLoss_D: 0.0635 tLoss_G: 5.6479 tD(x): 0.9975 tD(G(z)): 0.0541 / 0.0103\n",
            "[300/300][50/86]tLoss_D: 0.0014 tLoss_G: 8.7240 tD(x): 0.9992 tD(G(z)): 0.0006 / 0.0005\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    # img_list = []\n",
        "    img_list2 = []\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    iters = 0\n",
        "\n",
        "    print(\"Starting Training Loop...\")\n",
        "    # For each epoch\n",
        "    for epoch in range(num_epochs):\n",
        "        # For each batch in the dataloader\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "            ## Train with all-real batch (진짜 데이터들로 학습)\n",
        "            netD.zero_grad()\n",
        "            # Format batch (배치사이즈, 사용할 디바이스에 맞게 조정)\n",
        "            real_cpu = data[0].to(device)\n",
        "            b_size = real_cpu.size(0)\n",
        "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "            # Forward pass real batch through D (진짜 데이터들로 이루어진 배치를 D에 통과)\n",
        "            output = netD(real_cpu).view(-1)\n",
        "            # Calculate loss on all-real batch(손실값 구함)\n",
        "            errD_real = criterion(output, label)\n",
        "            # Calculate gradients for D in backward pass (역전파 과정에서 변화도 계산)\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            ## Train with all-fake batch (가짜 데이터들로 학습)\n",
        "            # Generate batch of latent vectors (벡터 생성)\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            # Generate fake image batch with G (G로 가짜 이미지 생성)\n",
        "            fake = netG(noise)\n",
        "            label.fill_(fake_label)\n",
        "            # Classify all fake batch with D (D로 판별)\n",
        "            output = netD(fake.detach()).view(-1)\n",
        "            # Calculate D's loss on the all-fake batch (D 손실값 계산)\n",
        "            errD_fake = criterion(output, label)\n",
        "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients(역전파로 변화도 계산 후 앞의 변화도에 더하기)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            # Compute error of D as sum over the fake and the real batches (가짜 이미지, 진짜 이미지 손실값 모두 더함)\n",
        "            errD = errD_real + errD_fake\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            ############################\n",
        "            # (2) Update G network: maximize log(D(G(z))) (G 신경망 업데이트)\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost (생성자 손실값 구하기 위해 진짜 라벨 이용)\n",
        "            # Since we just updated D, perform another forward pass of all-fake batch through D (D가 방금 업데이트 됐기 때문에 다시 D에 가짜 데이터 통과)\n",
        "            output = netD(fake).view(-1)\n",
        "            # Calculate G's loss based on this output (G 손실값 구하기)\n",
        "            errG = criterion(output, label)\n",
        "            # Calculate gradients for G (G 변화도 계산)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "            # Update G\n",
        "            optimizerG.step()\n",
        "\n",
        "            # 훈련상태 출력\n",
        "            if i % 50 == 0:\n",
        "                print('[%d/%d][%d/%d]tLoss_D: %.4f tLoss_G: %.4f tD(x): %.4f tD(G(z)): %.4f / %.4f'\n",
        "                    % (epoch+1, num_epochs, i, len(dataloader),\n",
        "                        errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            # 그래프 위해 손실값 저장\n",
        "            G_losses.append(errG.item())\n",
        "            D_losses.append(errD.item())\n",
        "     \n",
        "            # fixed_noise 통과시킨 G의 출력값 저장\n",
        "            # if (iters % 50 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            #     with torch.no_grad():\n",
        "            #         fake = netG(fixed_noise).detach().cpu()\n",
        "            #     img_list.append(vutils.make_grid(fake, padding=2, nrow=1, normalize=True))\n",
        "\n",
        "            # 이미지 저장\n",
        "            if epoch == (num_epochs-1):\n",
        "                for j in range(len(data[1])):\n",
        "                    if data[1][j] == 0:\n",
        "                        save_image(fake[j],'/content/dcgan_Result_b8_e300_lr0002_1205/cyst/DCGAN_cyst_%s.jpg' %(n1),'JPEG')\n",
        "                        n1 += 1\n",
        "                    if data[1][j] == 1:\n",
        "                        save_image(fake[j],'/content/dcgan_Result_b8_e300_lr0002_1205/hema/DCGAN_hema_%s.jpg' %(n2),'JPEG')\n",
        "                        n2 += 1\n",
        "                    if data[1][j] == 2:\n",
        "                        save_image(fake[j],'/content/dcgan_Result_b8_e300_lr0002_1205/meta/DCGAN_meta_%s.jpg' %(n3),'JPEG')\n",
        "                        n3 += 1\n",
        "\n",
        "            img_list2.append(fake)\n",
        "            iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_list2)"
      ],
      "metadata": {
        "id": "j7S5b4jfjGRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f975c6-5170-4ad4-8565-fcd0a838d847"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25800"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "netG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "eVmK_335WqId",
        "outputId": "f8bdc076-fb9a-42ea-e9c2-fccadf1e50d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-69f3eae610ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'netG' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "mZGsXH1m34oI",
        "outputId": "61b6db54-cc3a-46c2-9061-6fe30eafe7a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#생성된 이미지 확인\n",
        "from torchvision.utils import save_image\n",
        "transform = transforms.Grayscale()\n",
        "\n",
        "save_image(img_list2[26699], 'image_name1-1.png')\n",
        "save_image(img_list2[26698], 'image_name1-2.png')\n",
        "save_image(img_list2[26697], 'image_name1-3.png')\n",
        "save_image(img_list2[26696], 'image_name1-4.png')\n",
        "save_image(img_list2[26695], 'image_name1-5.png')\n",
        "save_image(img_list2[26694], 'image_name1-6.png')\n",
        "# save_image(img_list2[6500], 'image_name1-7.png')\n",
        "# save_image(img_list2[6600], 'image_name1-8.png')\n",
        "# save_image(img_list2[6700], 'image_name1-9.png')"
      ],
      "metadata": {
        "id": "HD-rWblb34qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/dcgan_hema_Result_1.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BmGxts-qjGZC",
        "outputId": "06c7fa45-f291-4c42-847d-a4d8a5d9a646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34f240db-4cb4-4f44-9b65-8bbb657ba820\", \"dcgan_hema_Result_1.zip\", 2301465)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_bQ7t2EZAk1"
      },
      "outputs": [],
      "source": [
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images (진짜 이미지 화면 출력)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "\n",
        "# Plot the fake images from the last epoch (가짜 이미지 화면 출력)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list2[-1],(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkTImPtjZAiO"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u2a38i_LTn_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finetuning"
      ],
      "metadata": {
        "id": "WK10XUscTpkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2K2qK3iTpmb",
        "outputId": "cb56a45f-875d-4f03-f2e4-5b0cac4acdb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.13.0+cu116\n",
            "Torchvision Version:  0.14.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = \"/content/drive/MyDrive/dataset_patch_220117/\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"vgg\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 3\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "metadata": {
        "id": "8AiW6z2mTppB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "XyZgDXSnTprY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "lAGVL1ATTpt8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox6fKrYyTpwV",
        "outputId": "2ee20f48-05e4-4ee8-fbb3-8a00278d7eb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oZ7neuosTpy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55e1c93-427b-46f7-cef6-6da7683bdc3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "sEG4vYt-Tp1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb7efa3-19c1-4d94-bbdb-f082de6924ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "metadata": {
        "id": "Yu1xFmwBTp33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5e8927-c4c2-4827-b7f3-3e2f7ed4bbe3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.9518 Acc: 0.6065\n",
            "val Loss: 1.1569 Acc: 0.3974\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.8504 Acc: 0.6300\n",
            "val Loss: 1.1165 Acc: 0.4272\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.8578 Acc: 0.6300\n",
            "val Loss: 0.8855 Acc: 0.5762\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.9123 Acc: 0.6153\n",
            "val Loss: 1.1571 Acc: 0.4371\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.8962 Acc: 0.6050\n",
            "val Loss: 0.9371 Acc: 0.5397\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.8603 Acc: 0.6226\n",
            "val Loss: 1.1402 Acc: 0.4735\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.8435 Acc: 0.6505\n",
            "val Loss: 1.1332 Acc: 0.4967\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.8263 Acc: 0.6490\n",
            "val Loss: 0.9322 Acc: 0.5596\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.9016 Acc: 0.5991\n",
            "val Loss: 0.9714 Acc: 0.5596\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.8606 Acc: 0.6432\n",
            "val Loss: 0.9397 Acc: 0.5728\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.8650 Acc: 0.6432\n",
            "val Loss: 0.9980 Acc: 0.5397\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.8332 Acc: 0.6520\n",
            "val Loss: 0.8870 Acc: 0.5762\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.8597 Acc: 0.6505\n",
            "val Loss: 0.9574 Acc: 0.5430\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.8875 Acc: 0.6388\n",
            "val Loss: 1.3260 Acc: 0.4503\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.8590 Acc: 0.6373\n",
            "val Loss: 1.0411 Acc: 0.5132\n",
            "\n",
            "Training complete in 2m 8s\n",
            "Best val Acc: 0.576159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the non-pretrained version of the model used for this run\n",
        "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "scratch_model = scratch_model.to(device)\n",
        "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scratch_criterion = nn.CrossEntropyLoss()\n",
        "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i5yV74P6Tp6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b288e2ab-8e4e-4daa-ce63-6f2391b185ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.8952 Acc: 0.5051\n",
            "val Loss: 8.1659 Acc: 0.3808\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 1.4919 Acc: 0.5433\n",
            "val Loss: 1.5560 Acc: 0.3808\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.3129 Acc: 0.5698\n",
            "val Loss: 1.5036 Acc: 0.4437\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.0377 Acc: 0.5800\n",
            "val Loss: 1.6141 Acc: 0.4007\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.1038 Acc: 0.5727\n",
            "val Loss: 1.2773 Acc: 0.3808\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.9823 Acc: 0.5962\n",
            "val Loss: 1.1486 Acc: 0.3874\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.9462 Acc: 0.6021\n",
            "val Loss: 1.0412 Acc: 0.4106\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.9401 Acc: 0.6035\n",
            "val Loss: 1.1277 Acc: 0.3841\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.9244 Acc: 0.6021\n",
            "val Loss: 1.3715 Acc: 0.3742\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.9356 Acc: 0.5991\n",
            "val Loss: 1.1657 Acc: 0.4040\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.9426 Acc: 0.6138\n",
            "val Loss: 1.1667 Acc: 0.4007\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.9059 Acc: 0.6167\n",
            "val Loss: 1.0964 Acc: 0.3808\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.9294 Acc: 0.6153\n",
            "val Loss: 1.2324 Acc: 0.3808\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9257 Acc: 0.6123\n",
            "val Loss: 1.0381 Acc: 0.4305\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.8784 Acc: 0.6182\n",
            "val Loss: 1.1626 Acc: 0.3874\n",
            "\n",
            "Training complete in 3m 8s\n",
            "Best val Acc: 0.443709\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPgWKM90Tp9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}